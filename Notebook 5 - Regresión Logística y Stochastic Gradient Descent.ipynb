{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 5: Regresión Logística - Un tutorial sobre Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "Para completar el trabajo de este notebook, se recomienda ver el material siguiente:\n",
    "- Videos Youtube: Curso de Andrew Ng sobre la Regresion Logística\n",
    "    - https://www.youtube.com/watch?v=-la3q9d7AKQ (Lecture 6.1 — Logistic Regression | Classification : 8 minutes)\n",
    "    - https://www.youtube.com/watch?v=t1IT5hZfS48 (Lecture 6.2 — Logistic Regression | Hypothesis Representation : 7 minutes)\n",
    "    - https://www.youtube.com/watch?v=F_VG4LNjZZw (Lecture 6.3 — Logistic Regression | Decision Boundary : 14 minutes)\n",
    "    - https://www.youtube.com/watch?v=HIQlmHxI6-0 (Lecture 6.4 — Logistic Regression | Cost Function : 11 minutes)\n",
    "    - https://www.youtube.com/watch?v=TTdcc21Ko9A (Lecture 6.5 — Logistic Regression | Simplified Cost Function And Gradient Descent : 10 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "La regresión logística es el algoritmo de clasificación lineal para problemas de dos clases.\n",
    "\n",
    "En este tutorial, descubrirá cómo implementar la regresión logística con el descenso de gradiente estocástico (stochastic gradient descent) desde cero con Python.\n",
    "\n",
    "Después de completar este tutorial, usted sabrá:\n",
    "\n",
    "- Cómo hacer predicciones con un modelo de regresión logística.\n",
    "- Cómo estimar los coeficientes utilizando el descenso de gradiente estocástico.\n",
    "- Cómo aplicar la regresión logística a un problema real de predicción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción\n",
    "\n",
    "Esta sección dará una breve descripción de la técnica de regresión logística, el descenso por gradiente estocástico y el dataset \"diabetes\" que utilizaremos en este tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "La regresión logística se denomina así por la función utilizada en el núcleo del método, la función logística.\n",
    "\n",
    "La regresión logística utiliza una ecuación como representación, muy similar a la regresión lineal. Los valores de entrada (X) se combinan linealmente utilizando pesos o valores de coeficiente para predecir un valor de salida (y).\n",
    "\n",
    "Una diferencia clave con respecto a la regresión lineal es que el valor de salida que se está modelando es un valor binario (0 ó 1) en lugar de un valor numérico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>yhat = e^(b0 + b1 * x1) / (1 + e^(b0 + b1 * x1))</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto puede simplificarse como:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>yhat = 1.0 / (1.0 + e^(-(b0 + b1 * x1)))</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde <b>e</b> es la base de los logaritmos naturales (el número de Euler), <b>yhat</b> es el resultado previsto, <b>b0</b> es el sesgo o término de intercepción y <b>b1</b> es el coeficiente para el valor de entrada simple (<b>x1</b>).\n",
    "\n",
    "La predicción <b>yhat</b> es un valor real entre 0 y 1, que necesita ser redondeado a un valor entero y mapeado a un valor de clase predicho.\n",
    "\n",
    "Cada columna de los datos de entrada tiene un coeficiente <b>b</b> asociado (un valor real constante) que debe aprenderse de los datos de entrenamiento. La representación real del modelo que almacenarías en memoria o en un archivo son los coeficientes de la ecuación.\n",
    "\n",
    "Los coeficientes del algoritmo de regresión logística deben estimarse a partir de los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descenso estocástico por gradiente (Stochastic Gradient Descent)\n",
    "\n",
    "El descenso por gradiente es el proceso de minimizar una función siguiendo los gradientes de la función de coste.\n",
    "\n",
    "Esto implica conocer la forma del coste así como la derivada para que desde un punto dado conozcas la pendiente y puedas moverte en esa dirección, por ejemplo, cuesta abajo hacia el valor mínimo.\n",
    "\n",
    "En el aprendizaje automático, podemos utilizar una técnica que evalúa y actualiza los coeficientes en cada iteración llamada descenso estocástico de gradiente para minimizar el error de un modelo en nuestros datos de entrenamiento.\n",
    "\n",
    "La forma en que funciona este algoritmo de optimización es que cada instancia de entrenamiento se muestra al modelo una por una. El modelo hace una predicción para una instancia de entrenamiento, se calcula el error y se actualiza el modelo para reducir el error para la siguiente predicción.\n",
    "\n",
    "Este procedimiento se puede utilizar para encontrar el conjunto de coeficientes en un modelo que da como resultado el menor error para el modelo en los datos de entrenamiento. En cada iteración, los coeficientes (b) se actualizan utilizando la ecuación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>b = b + learning_rate * (y - yhat) * yhat * (1 - yhat) * x</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde <b>b</b> es el coeficiente o peso que se está optimizando, <b>learning_rate</b> es una velocidad de aprendizaje que se debe configurar (por ejemplo, 0.01), <b>(y - yhat)</b> es el error de predicción para el modelo en los datos de entrenamiento atribuidos al peso, <b>yhat</b> es la predicción hecha por los coeficientes y <b>x</b> es el valor de entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset y Problema de clasificación\n",
    "\n",
    "El dataset \"diabetes.csv\" consiste en predecir el inicio de la diabetes en un plazo de 5 años en los indios Pima a los que se les dan detalles médicos básicos.\n",
    "\n",
    "Es un problema de clasificación binaria, donde la predicción es 0 (sin diabetes) o 1 (diabetes).\n",
    "\n",
    "Contiene 768 filas y 9 columnas. Todos los valores en el archivo son numéricos, específicamente valores en coma flotante. Abajo hay una pequeña muestra de las primeras filas del problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>6,148,72,35,0,33.6,0.627,50,1\n",
    "1,85,66,29,0,26.6,0.351,31,0\n",
    "8,183,64,0,0,23.3,0.672,32,1\n",
    "1,89,66,23,94,28.1,0.167,21,0\n",
    "0,137,40,35,168,43.1,2.288,33,1\n",
    "...</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial\n",
    "\n",
    "Este tutorial está dividido en 3 partes.\n",
    "\n",
    "    - Hacer predicciones.\n",
    "    - Estimar los Coeficientes de la regresión logística\n",
    "    - Predecir el diabete.\n",
    "\n",
    "Esto le proporcionará la base que necesita para implementar y aplicar la regresión logística con descenso de gradiente estocástico sobre sus propios problemas de modelado predictivo.\n",
    "\n",
    "### 1. Hacer predicciones\n",
    "\n",
    "El primer paso es desarrollar una función que pueda hacer predicciones.\n",
    "\n",
    "Esto será necesario tanto en la evaluación de los valores de los coeficientes candidatos en el descenso del gradiente estocástico como después de que se finalice el modelo y queramos empezar a hacer predicciones sobre los datos de prueba o nuevos datos.\n",
    "\n",
    "Abajo hay una función llamada predict() que predice un valor de salida para una fila con un conjunto de coeficientes.\n",
    "\n",
    "El primer coeficiente en es siempre la intercepción, también llamado el sesgo o b0 ya que es independiente y no es responsable de un valor de entrada específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "\n",
    "# Make a prediction with coefficients\n",
    "def predict(row, coefficients):\n",
    "    yhat = coefficients[0]\n",
    "    for i in range(len(row)-1):\n",
    "        yhat += coefficients[i + 1] * row[i]\n",
    "    return 1.0 / (1.0 + exp(-yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos crear un pequeño conjunto de datos para probar nuestra función predict()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test predictions\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "[1.465489372,2.362125076,0],\n",
    "[3.396561688,4.400293529,0],\n",
    "[1.38807019,1.850220317,0],\n",
    "[3.06407232,3.005305973,0],\n",
    "[7.627531214,2.759262235,1],\n",
    "[5.332441248,2.088626775,1],\n",
    "[6.922596716,1.77106367,1],\n",
    "[8.675418651,-0.242068655,1],\n",
    "[7.673756466,3.508563011,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>PREGUNTA:</b>\n",
    "\n",
    "con Pandas y Matplotlib, construir un gráfico en dos dimensiones (x1 y x2), posicionando cada punto del dataset y diferenciando los puntos de cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.DataFrame(dataset, columns=['x1','x2','y'])\n",
    "for i in dataset:\n",
    "    if i[2]==0:\n",
    "        plt.scatter(x=i[0], y=i[1], c='r')    \n",
    "    else:\n",
    "        plt.scatter(x=i[0], y=i[1], c='g')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar coeficientes (b0, b1, b2) previamente preparados para hacer predicciones para este conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = [-0.406605464, 0.852573316, -1.104746259]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniendo todo esto junto podemos probar nuestra función predict() a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected=0.000, Predicted=0.299 [0]\n",
      "Expected=0.000, Predicted=0.146 [0]\n",
      "Expected=0.000, Predicted=0.085 [0]\n",
      "Expected=0.000, Predicted=0.220 [0]\n",
      "Expected=0.000, Predicted=0.247 [0]\n",
      "Expected=1.000, Predicted=0.955 [1]\n",
      "Expected=1.000, Predicted=0.862 [1]\n",
      "Expected=1.000, Predicted=0.972 [1]\n",
      "Expected=1.000, Predicted=0.999 [1]\n",
      "Expected=1.000, Predicted=0.905 [1]\n"
     ]
    }
   ],
   "source": [
    "for row in dataset:\n",
    "    yhat = predict(row, coef)\n",
    "    print(\"Expected=%.3f, Predicted=%.3f [%d]\" % (row[-1], yhat, round(yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>PREGUNTA:</b> ¿Cuál es la precisión y el recall de nuestro modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por supuesto, en la realidad no podemos adivinar los buenos coeficientes b. Necesitamos un metodo para aproximar los mejores coeficientes. Presentamos a continuación el método Stochastic Gradient Descent que apunta a este objetivo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estimación de los coeficientes\n",
    "\n",
    "Podemos estimar los valores del coeficiente para nuestros datos de entrenamiento utilizando el descenso de gradiente estocástico.\n",
    "\n",
    "El descenso estocástico por gradiente requiere dos parámetros:\n",
    "\n",
    "    - Tasa de Aprendizaje (Learning rate): Se utiliza para limitar el importe que cada coeficiente se corrige cada vez que se actualiza.\n",
    "    - Épocas (Epochs): El número de veces que se repasan los datos de entrenamiento mientras se actualizan los coeficientes.\n",
    "\n",
    "Estos, junto con los datos de la formación, serán los argumentos de la función.\n",
    "\n",
    "Hay 3 bucles que necesitamos realizar en la función:\n",
    "\n",
    "    - Bucle sobre cada época.\n",
    "    - Bucle sobre cada fila de los datos de entrenamiento de una época.\n",
    "    - Bucle sobre cada coeficiente y actualícelo para una fila en una época.\n",
    "\n",
    "Como puedes ver, actualizamos cada coeficiente para cada fila de los datos de entrenamiento, cada época.\n",
    "\n",
    "Los coeficientes se actualizan en función del error que cometió el modelo. El error se calcula como la diferencia entre el valor de salida esperado y la predicción realizada con los coeficientes candidatos.\n",
    "\n",
    "Hay un coeficiente para ponderar cada atributo de entrada, y éstos se actualizan de forma coherente, por ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>b1(t+1) = b1(t) + learning_rate * (y(t) - yhat(t)) * yhat(t) * (1 - yhat(t)) * x1(t)</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El coeficiente especial al principio de la lista, también llamado intercepción, se actualiza de forma similar, excepto sin una entrada, ya que no está asociado a un valor de entrada específico:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>b0(t+1) = b0(t) + learning_rate * (y(t) - yhat(t)) * yhat(t) * (1 - yhat(t))</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos juntar todo esto. A continuación se muestra una función llamada <b>coefficients_sgd()</b> que calcula los valores de los coeficientes para un conjunto de datos de entrenamiento utilizando el descenso de gradiente estocástico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate logistic regression coefficients using stochastic gradient descent\n",
    "def coefficients_sgd(train, l_rate, n_epoch):\n",
    "    coef = [0.0 for i in range(len(train[0]))]\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            yhat = predict(row, coef)\n",
    "            error = row[-1] - yhat\n",
    "            sum_error += error**2\n",
    "            coef[0] = coef[0] + l_rate * error * yhat * (1.0 - yhat)\n",
    "            for i in range(len(row)-1):\n",
    "                coef[i + 1] = coef[i + 1] + l_rate * error * yhat * (1.0 - yhat) * row[i]\n",
    "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "    return coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes ver, que además, llevamos la cuenta de la suma del error al cuadrado (un valor positivo) de cada época para que podamos imprimir un bonito mensaje en cada bucle exterior.\n",
    "\n",
    "Podemos probar esta función en el mismo pequeño conjunto de datos creado desde arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate coefficients\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "    [1.465489372,2.362125076,0],\n",
    "    [3.396561688,4.400293529,0],\n",
    "    [1.38807019,1.850220317,0],\n",
    "    [3.06407232,3.005305973,0],\n",
    "    [7.627531214,2.759262235,1],\n",
    "    [5.332441248,2.088626775,1],\n",
    "    [6.922596716,1.77106367,1],\n",
    "    [8.675418651,-0.242068655,1],\n",
    "    [7.673756466,3.508563011,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos una mayor tasa de aprendizaje de 0,3 y entrenamos el modelo para 100 épocas, o 100 exposiciones de los coeficientes a todo el conjunto de datos de entrenamiento.\n",
    "\n",
    "Al ejecutar el ejemplo se imprime un mensaje en cada época con la suma del error al cuadrado para esa época y el conjunto final de coeficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.300, error=2.217\n",
      ">epoch=1, lrate=0.300, error=1.613\n",
      ">epoch=2, lrate=0.300, error=1.113\n",
      ">epoch=3, lrate=0.300, error=0.827\n",
      ">epoch=4, lrate=0.300, error=0.623\n",
      ">epoch=5, lrate=0.300, error=0.494\n",
      ">epoch=6, lrate=0.300, error=0.412\n",
      ">epoch=7, lrate=0.300, error=0.354\n",
      ">epoch=8, lrate=0.300, error=0.310\n",
      ">epoch=9, lrate=0.300, error=0.276\n",
      ">epoch=10, lrate=0.300, error=0.248\n",
      ">epoch=11, lrate=0.300, error=0.224\n",
      ">epoch=12, lrate=0.300, error=0.205\n",
      ">epoch=13, lrate=0.300, error=0.189\n",
      ">epoch=14, lrate=0.300, error=0.174\n",
      ">epoch=15, lrate=0.300, error=0.162\n",
      ">epoch=16, lrate=0.300, error=0.151\n",
      ">epoch=17, lrate=0.300, error=0.142\n",
      ">epoch=18, lrate=0.300, error=0.134\n",
      ">epoch=19, lrate=0.300, error=0.126\n",
      ">epoch=20, lrate=0.300, error=0.119\n",
      ">epoch=21, lrate=0.300, error=0.113\n",
      ">epoch=22, lrate=0.300, error=0.108\n",
      ">epoch=23, lrate=0.300, error=0.103\n",
      ">epoch=24, lrate=0.300, error=0.098\n",
      ">epoch=25, lrate=0.300, error=0.094\n",
      ">epoch=26, lrate=0.300, error=0.090\n",
      ">epoch=27, lrate=0.300, error=0.087\n",
      ">epoch=28, lrate=0.300, error=0.084\n",
      ">epoch=29, lrate=0.300, error=0.080\n",
      ">epoch=30, lrate=0.300, error=0.078\n",
      ">epoch=31, lrate=0.300, error=0.075\n",
      ">epoch=32, lrate=0.300, error=0.073\n",
      ">epoch=33, lrate=0.300, error=0.070\n",
      ">epoch=34, lrate=0.300, error=0.068\n",
      ">epoch=35, lrate=0.300, error=0.066\n",
      ">epoch=36, lrate=0.300, error=0.064\n",
      ">epoch=37, lrate=0.300, error=0.062\n",
      ">epoch=38, lrate=0.300, error=0.060\n",
      ">epoch=39, lrate=0.300, error=0.059\n",
      ">epoch=40, lrate=0.300, error=0.057\n",
      ">epoch=41, lrate=0.300, error=0.056\n",
      ">epoch=42, lrate=0.300, error=0.054\n",
      ">epoch=43, lrate=0.300, error=0.053\n",
      ">epoch=44, lrate=0.300, error=0.052\n",
      ">epoch=45, lrate=0.300, error=0.051\n",
      ">epoch=46, lrate=0.300, error=0.050\n",
      ">epoch=47, lrate=0.300, error=0.048\n",
      ">epoch=48, lrate=0.300, error=0.047\n",
      ">epoch=49, lrate=0.300, error=0.046\n",
      ">epoch=50, lrate=0.300, error=0.045\n",
      ">epoch=51, lrate=0.300, error=0.044\n",
      ">epoch=52, lrate=0.300, error=0.044\n",
      ">epoch=53, lrate=0.300, error=0.043\n",
      ">epoch=54, lrate=0.300, error=0.042\n",
      ">epoch=55, lrate=0.300, error=0.041\n",
      ">epoch=56, lrate=0.300, error=0.040\n",
      ">epoch=57, lrate=0.300, error=0.040\n",
      ">epoch=58, lrate=0.300, error=0.039\n",
      ">epoch=59, lrate=0.300, error=0.038\n",
      ">epoch=60, lrate=0.300, error=0.038\n",
      ">epoch=61, lrate=0.300, error=0.037\n",
      ">epoch=62, lrate=0.300, error=0.036\n",
      ">epoch=63, lrate=0.300, error=0.036\n",
      ">epoch=64, lrate=0.300, error=0.035\n",
      ">epoch=65, lrate=0.300, error=0.035\n",
      ">epoch=66, lrate=0.300, error=0.034\n",
      ">epoch=67, lrate=0.300, error=0.033\n",
      ">epoch=68, lrate=0.300, error=0.033\n",
      ">epoch=69, lrate=0.300, error=0.032\n",
      ">epoch=70, lrate=0.300, error=0.032\n",
      ">epoch=71, lrate=0.300, error=0.032\n",
      ">epoch=72, lrate=0.300, error=0.031\n",
      ">epoch=73, lrate=0.300, error=0.031\n",
      ">epoch=74, lrate=0.300, error=0.030\n",
      ">epoch=75, lrate=0.300, error=0.030\n",
      ">epoch=76, lrate=0.300, error=0.029\n",
      ">epoch=77, lrate=0.300, error=0.029\n",
      ">epoch=78, lrate=0.300, error=0.029\n",
      ">epoch=79, lrate=0.300, error=0.028\n",
      ">epoch=80, lrate=0.300, error=0.028\n",
      ">epoch=81, lrate=0.300, error=0.027\n",
      ">epoch=82, lrate=0.300, error=0.027\n",
      ">epoch=83, lrate=0.300, error=0.027\n",
      ">epoch=84, lrate=0.300, error=0.026\n",
      ">epoch=85, lrate=0.300, error=0.026\n",
      ">epoch=86, lrate=0.300, error=0.026\n",
      ">epoch=87, lrate=0.300, error=0.026\n",
      ">epoch=88, lrate=0.300, error=0.025\n",
      ">epoch=89, lrate=0.300, error=0.025\n",
      ">epoch=90, lrate=0.300, error=0.025\n",
      ">epoch=91, lrate=0.300, error=0.024\n",
      ">epoch=92, lrate=0.300, error=0.024\n",
      ">epoch=93, lrate=0.300, error=0.024\n",
      ">epoch=94, lrate=0.300, error=0.024\n",
      ">epoch=95, lrate=0.300, error=0.023\n",
      ">epoch=96, lrate=0.300, error=0.023\n",
      ">epoch=97, lrate=0.300, error=0.023\n",
      ">epoch=98, lrate=0.300, error=0.023\n",
      ">epoch=99, lrate=0.300, error=0.022\n",
      ">epoch=100, lrate=0.300, error=0.022\n",
      ">epoch=101, lrate=0.300, error=0.022\n",
      ">epoch=102, lrate=0.300, error=0.022\n",
      ">epoch=103, lrate=0.300, error=0.021\n",
      ">epoch=104, lrate=0.300, error=0.021\n",
      ">epoch=105, lrate=0.300, error=0.021\n",
      ">epoch=106, lrate=0.300, error=0.021\n",
      ">epoch=107, lrate=0.300, error=0.021\n",
      ">epoch=108, lrate=0.300, error=0.020\n",
      ">epoch=109, lrate=0.300, error=0.020\n",
      ">epoch=110, lrate=0.300, error=0.020\n",
      ">epoch=111, lrate=0.300, error=0.020\n",
      ">epoch=112, lrate=0.300, error=0.020\n",
      ">epoch=113, lrate=0.300, error=0.020\n",
      ">epoch=114, lrate=0.300, error=0.019\n",
      ">epoch=115, lrate=0.300, error=0.019\n",
      ">epoch=116, lrate=0.300, error=0.019\n",
      ">epoch=117, lrate=0.300, error=0.019\n",
      ">epoch=118, lrate=0.300, error=0.019\n",
      ">epoch=119, lrate=0.300, error=0.018\n",
      ">epoch=120, lrate=0.300, error=0.018\n",
      ">epoch=121, lrate=0.300, error=0.018\n",
      ">epoch=122, lrate=0.300, error=0.018\n",
      ">epoch=123, lrate=0.300, error=0.018\n",
      ">epoch=124, lrate=0.300, error=0.018\n",
      ">epoch=125, lrate=0.300, error=0.018\n",
      ">epoch=126, lrate=0.300, error=0.017\n",
      ">epoch=127, lrate=0.300, error=0.017\n",
      ">epoch=128, lrate=0.300, error=0.017\n",
      ">epoch=129, lrate=0.300, error=0.017\n",
      ">epoch=130, lrate=0.300, error=0.017\n",
      ">epoch=131, lrate=0.300, error=0.017\n",
      ">epoch=132, lrate=0.300, error=0.017\n",
      ">epoch=133, lrate=0.300, error=0.017\n",
      ">epoch=134, lrate=0.300, error=0.016\n",
      ">epoch=135, lrate=0.300, error=0.016\n",
      ">epoch=136, lrate=0.300, error=0.016\n",
      ">epoch=137, lrate=0.300, error=0.016\n",
      ">epoch=138, lrate=0.300, error=0.016\n",
      ">epoch=139, lrate=0.300, error=0.016\n",
      ">epoch=140, lrate=0.300, error=0.016\n",
      ">epoch=141, lrate=0.300, error=0.016\n",
      ">epoch=142, lrate=0.300, error=0.015\n",
      ">epoch=143, lrate=0.300, error=0.015\n",
      ">epoch=144, lrate=0.300, error=0.015\n",
      ">epoch=145, lrate=0.300, error=0.015\n",
      ">epoch=146, lrate=0.300, error=0.015\n",
      ">epoch=147, lrate=0.300, error=0.015\n",
      ">epoch=148, lrate=0.300, error=0.015\n",
      ">epoch=149, lrate=0.300, error=0.015\n",
      ">epoch=150, lrate=0.300, error=0.015\n",
      ">epoch=151, lrate=0.300, error=0.014\n",
      ">epoch=152, lrate=0.300, error=0.014\n",
      ">epoch=153, lrate=0.300, error=0.014\n",
      ">epoch=154, lrate=0.300, error=0.014\n",
      ">epoch=155, lrate=0.300, error=0.014\n",
      ">epoch=156, lrate=0.300, error=0.014\n",
      ">epoch=157, lrate=0.300, error=0.014\n",
      ">epoch=158, lrate=0.300, error=0.014\n",
      ">epoch=159, lrate=0.300, error=0.014\n",
      ">epoch=160, lrate=0.300, error=0.014\n",
      ">epoch=161, lrate=0.300, error=0.014\n",
      ">epoch=162, lrate=0.300, error=0.013\n",
      ">epoch=163, lrate=0.300, error=0.013\n",
      ">epoch=164, lrate=0.300, error=0.013\n",
      ">epoch=165, lrate=0.300, error=0.013\n",
      ">epoch=166, lrate=0.300, error=0.013\n",
      ">epoch=167, lrate=0.300, error=0.013\n",
      ">epoch=168, lrate=0.300, error=0.013\n",
      ">epoch=169, lrate=0.300, error=0.013\n",
      ">epoch=170, lrate=0.300, error=0.013\n",
      ">epoch=171, lrate=0.300, error=0.013\n",
      ">epoch=172, lrate=0.300, error=0.013\n",
      ">epoch=173, lrate=0.300, error=0.013\n",
      ">epoch=174, lrate=0.300, error=0.013\n",
      ">epoch=175, lrate=0.300, error=0.012\n",
      ">epoch=176, lrate=0.300, error=0.012\n",
      ">epoch=177, lrate=0.300, error=0.012\n",
      ">epoch=178, lrate=0.300, error=0.012\n",
      ">epoch=179, lrate=0.300, error=0.012\n",
      ">epoch=180, lrate=0.300, error=0.012\n",
      ">epoch=181, lrate=0.300, error=0.012\n",
      ">epoch=182, lrate=0.300, error=0.012\n",
      ">epoch=183, lrate=0.300, error=0.012\n",
      ">epoch=184, lrate=0.300, error=0.012\n",
      ">epoch=185, lrate=0.300, error=0.012\n",
      ">epoch=186, lrate=0.300, error=0.012\n",
      ">epoch=187, lrate=0.300, error=0.012\n",
      ">epoch=188, lrate=0.300, error=0.012\n",
      ">epoch=189, lrate=0.300, error=0.012\n",
      ">epoch=190, lrate=0.300, error=0.011\n",
      ">epoch=191, lrate=0.300, error=0.011\n",
      ">epoch=192, lrate=0.300, error=0.011\n",
      ">epoch=193, lrate=0.300, error=0.011\n",
      ">epoch=194, lrate=0.300, error=0.011\n",
      ">epoch=195, lrate=0.300, error=0.011\n",
      ">epoch=196, lrate=0.300, error=0.011\n",
      ">epoch=197, lrate=0.300, error=0.011\n",
      ">epoch=198, lrate=0.300, error=0.011\n",
      ">epoch=199, lrate=0.300, error=0.011\n",
      ">epoch=200, lrate=0.300, error=0.011\n",
      ">epoch=201, lrate=0.300, error=0.011\n",
      ">epoch=202, lrate=0.300, error=0.011\n",
      ">epoch=203, lrate=0.300, error=0.011\n",
      ">epoch=204, lrate=0.300, error=0.011\n",
      ">epoch=205, lrate=0.300, error=0.011\n",
      ">epoch=206, lrate=0.300, error=0.011\n",
      ">epoch=207, lrate=0.300, error=0.011\n",
      ">epoch=208, lrate=0.300, error=0.010\n",
      ">epoch=209, lrate=0.300, error=0.010\n",
      ">epoch=210, lrate=0.300, error=0.010\n",
      ">epoch=211, lrate=0.300, error=0.010\n",
      ">epoch=212, lrate=0.300, error=0.010\n",
      ">epoch=213, lrate=0.300, error=0.010\n",
      ">epoch=214, lrate=0.300, error=0.010\n",
      ">epoch=215, lrate=0.300, error=0.010\n",
      ">epoch=216, lrate=0.300, error=0.010\n",
      ">epoch=217, lrate=0.300, error=0.010\n",
      ">epoch=218, lrate=0.300, error=0.010\n",
      ">epoch=219, lrate=0.300, error=0.010\n",
      ">epoch=220, lrate=0.300, error=0.010\n",
      ">epoch=221, lrate=0.300, error=0.010\n",
      ">epoch=222, lrate=0.300, error=0.010\n",
      ">epoch=223, lrate=0.300, error=0.010\n",
      ">epoch=224, lrate=0.300, error=0.010\n",
      ">epoch=225, lrate=0.300, error=0.010\n",
      ">epoch=226, lrate=0.300, error=0.010\n",
      ">epoch=227, lrate=0.300, error=0.010\n",
      ">epoch=228, lrate=0.300, error=0.010\n",
      ">epoch=229, lrate=0.300, error=0.009\n",
      ">epoch=230, lrate=0.300, error=0.009\n",
      ">epoch=231, lrate=0.300, error=0.009\n",
      ">epoch=232, lrate=0.300, error=0.009\n",
      ">epoch=233, lrate=0.300, error=0.009\n",
      ">epoch=234, lrate=0.300, error=0.009\n",
      ">epoch=235, lrate=0.300, error=0.009\n",
      ">epoch=236, lrate=0.300, error=0.009\n",
      ">epoch=237, lrate=0.300, error=0.009\n",
      ">epoch=238, lrate=0.300, error=0.009\n",
      ">epoch=239, lrate=0.300, error=0.009\n",
      ">epoch=240, lrate=0.300, error=0.009\n",
      ">epoch=241, lrate=0.300, error=0.009\n",
      ">epoch=242, lrate=0.300, error=0.009\n",
      ">epoch=243, lrate=0.300, error=0.009\n",
      ">epoch=244, lrate=0.300, error=0.009\n",
      ">epoch=245, lrate=0.300, error=0.009\n",
      ">epoch=246, lrate=0.300, error=0.009\n",
      ">epoch=247, lrate=0.300, error=0.009\n",
      ">epoch=248, lrate=0.300, error=0.009\n",
      ">epoch=249, lrate=0.300, error=0.009\n",
      ">epoch=250, lrate=0.300, error=0.009\n",
      ">epoch=251, lrate=0.300, error=0.009\n",
      ">epoch=252, lrate=0.300, error=0.009\n",
      ">epoch=253, lrate=0.300, error=0.009\n",
      ">epoch=254, lrate=0.300, error=0.009\n",
      ">epoch=255, lrate=0.300, error=0.008\n",
      ">epoch=256, lrate=0.300, error=0.008\n",
      ">epoch=257, lrate=0.300, error=0.008\n",
      ">epoch=258, lrate=0.300, error=0.008\n",
      ">epoch=259, lrate=0.300, error=0.008\n",
      ">epoch=260, lrate=0.300, error=0.008\n",
      ">epoch=261, lrate=0.300, error=0.008\n",
      ">epoch=262, lrate=0.300, error=0.008\n",
      ">epoch=263, lrate=0.300, error=0.008\n",
      ">epoch=264, lrate=0.300, error=0.008\n",
      ">epoch=265, lrate=0.300, error=0.008\n",
      ">epoch=266, lrate=0.300, error=0.008\n",
      ">epoch=267, lrate=0.300, error=0.008\n",
      ">epoch=268, lrate=0.300, error=0.008\n",
      ">epoch=269, lrate=0.300, error=0.008\n",
      ">epoch=270, lrate=0.300, error=0.008\n",
      ">epoch=271, lrate=0.300, error=0.008\n",
      ">epoch=272, lrate=0.300, error=0.008\n",
      ">epoch=273, lrate=0.300, error=0.008\n",
      ">epoch=274, lrate=0.300, error=0.008\n",
      ">epoch=275, lrate=0.300, error=0.008\n",
      ">epoch=276, lrate=0.300, error=0.008\n",
      ">epoch=277, lrate=0.300, error=0.008\n",
      ">epoch=278, lrate=0.300, error=0.008\n",
      ">epoch=279, lrate=0.300, error=0.008\n",
      ">epoch=280, lrate=0.300, error=0.008\n",
      ">epoch=281, lrate=0.300, error=0.008\n",
      ">epoch=282, lrate=0.300, error=0.008\n",
      ">epoch=283, lrate=0.300, error=0.008\n",
      ">epoch=284, lrate=0.300, error=0.008\n",
      ">epoch=285, lrate=0.300, error=0.008\n",
      ">epoch=286, lrate=0.300, error=0.008\n",
      ">epoch=287, lrate=0.300, error=0.008\n",
      ">epoch=288, lrate=0.300, error=0.008\n",
      ">epoch=289, lrate=0.300, error=0.007\n",
      ">epoch=290, lrate=0.300, error=0.007\n",
      ">epoch=291, lrate=0.300, error=0.007\n",
      ">epoch=292, lrate=0.300, error=0.007\n",
      ">epoch=293, lrate=0.300, error=0.007\n",
      ">epoch=294, lrate=0.300, error=0.007\n",
      ">epoch=295, lrate=0.300, error=0.007\n",
      ">epoch=296, lrate=0.300, error=0.007\n",
      ">epoch=297, lrate=0.300, error=0.007\n",
      ">epoch=298, lrate=0.300, error=0.007\n",
      ">epoch=299, lrate=0.300, error=0.007\n",
      ">epoch=300, lrate=0.300, error=0.007\n",
      ">epoch=301, lrate=0.300, error=0.007\n",
      ">epoch=302, lrate=0.300, error=0.007\n",
      ">epoch=303, lrate=0.300, error=0.007\n",
      ">epoch=304, lrate=0.300, error=0.007\n",
      ">epoch=305, lrate=0.300, error=0.007\n",
      ">epoch=306, lrate=0.300, error=0.007\n",
      ">epoch=307, lrate=0.300, error=0.007\n",
      ">epoch=308, lrate=0.300, error=0.007\n",
      ">epoch=309, lrate=0.300, error=0.007\n",
      ">epoch=310, lrate=0.300, error=0.007\n",
      ">epoch=311, lrate=0.300, error=0.007\n",
      ">epoch=312, lrate=0.300, error=0.007\n",
      ">epoch=313, lrate=0.300, error=0.007\n",
      ">epoch=314, lrate=0.300, error=0.007\n",
      ">epoch=315, lrate=0.300, error=0.007\n",
      ">epoch=316, lrate=0.300, error=0.007\n",
      ">epoch=317, lrate=0.300, error=0.007\n",
      ">epoch=318, lrate=0.300, error=0.007\n",
      ">epoch=319, lrate=0.300, error=0.007\n",
      ">epoch=320, lrate=0.300, error=0.007\n",
      ">epoch=321, lrate=0.300, error=0.007\n",
      ">epoch=322, lrate=0.300, error=0.007\n",
      ">epoch=323, lrate=0.300, error=0.007\n",
      ">epoch=324, lrate=0.300, error=0.007\n",
      ">epoch=325, lrate=0.300, error=0.007\n",
      ">epoch=326, lrate=0.300, error=0.007\n",
      ">epoch=327, lrate=0.300, error=0.007\n",
      ">epoch=328, lrate=0.300, error=0.007\n",
      ">epoch=329, lrate=0.300, error=0.007\n",
      ">epoch=330, lrate=0.300, error=0.007\n",
      ">epoch=331, lrate=0.300, error=0.007\n",
      ">epoch=332, lrate=0.300, error=0.007\n",
      ">epoch=333, lrate=0.300, error=0.006\n",
      ">epoch=334, lrate=0.300, error=0.006\n",
      ">epoch=335, lrate=0.300, error=0.006\n",
      ">epoch=336, lrate=0.300, error=0.006\n",
      ">epoch=337, lrate=0.300, error=0.006\n",
      ">epoch=338, lrate=0.300, error=0.006\n",
      ">epoch=339, lrate=0.300, error=0.006\n",
      ">epoch=340, lrate=0.300, error=0.006\n",
      ">epoch=341, lrate=0.300, error=0.006\n",
      ">epoch=342, lrate=0.300, error=0.006\n",
      ">epoch=343, lrate=0.300, error=0.006\n",
      ">epoch=344, lrate=0.300, error=0.006\n",
      ">epoch=345, lrate=0.300, error=0.006\n",
      ">epoch=346, lrate=0.300, error=0.006\n",
      ">epoch=347, lrate=0.300, error=0.006\n",
      ">epoch=348, lrate=0.300, error=0.006\n",
      ">epoch=349, lrate=0.300, error=0.006\n",
      ">epoch=350, lrate=0.300, error=0.006\n",
      ">epoch=351, lrate=0.300, error=0.006\n",
      ">epoch=352, lrate=0.300, error=0.006\n",
      ">epoch=353, lrate=0.300, error=0.006\n",
      ">epoch=354, lrate=0.300, error=0.006\n",
      ">epoch=355, lrate=0.300, error=0.006\n",
      ">epoch=356, lrate=0.300, error=0.006\n",
      ">epoch=357, lrate=0.300, error=0.006\n",
      ">epoch=358, lrate=0.300, error=0.006\n",
      ">epoch=359, lrate=0.300, error=0.006\n",
      ">epoch=360, lrate=0.300, error=0.006\n",
      ">epoch=361, lrate=0.300, error=0.006\n",
      ">epoch=362, lrate=0.300, error=0.006\n",
      ">epoch=363, lrate=0.300, error=0.006\n",
      ">epoch=364, lrate=0.300, error=0.006\n",
      ">epoch=365, lrate=0.300, error=0.006\n",
      ">epoch=366, lrate=0.300, error=0.006\n",
      ">epoch=367, lrate=0.300, error=0.006\n",
      ">epoch=368, lrate=0.300, error=0.006\n",
      ">epoch=369, lrate=0.300, error=0.006\n",
      ">epoch=370, lrate=0.300, error=0.006\n",
      ">epoch=371, lrate=0.300, error=0.006\n",
      ">epoch=372, lrate=0.300, error=0.006\n",
      ">epoch=373, lrate=0.300, error=0.006\n",
      ">epoch=374, lrate=0.300, error=0.006\n",
      ">epoch=375, lrate=0.300, error=0.006\n",
      ">epoch=376, lrate=0.300, error=0.006\n",
      ">epoch=377, lrate=0.300, error=0.006\n",
      ">epoch=378, lrate=0.300, error=0.006\n",
      ">epoch=379, lrate=0.300, error=0.006\n",
      ">epoch=380, lrate=0.300, error=0.006\n",
      ">epoch=381, lrate=0.300, error=0.006\n",
      ">epoch=382, lrate=0.300, error=0.006\n",
      ">epoch=383, lrate=0.300, error=0.006\n",
      ">epoch=384, lrate=0.300, error=0.006\n",
      ">epoch=385, lrate=0.300, error=0.006\n",
      ">epoch=386, lrate=0.300, error=0.006\n",
      ">epoch=387, lrate=0.300, error=0.006\n",
      ">epoch=388, lrate=0.300, error=0.006\n",
      ">epoch=389, lrate=0.300, error=0.006\n",
      ">epoch=390, lrate=0.300, error=0.006\n",
      ">epoch=391, lrate=0.300, error=0.006\n",
      ">epoch=392, lrate=0.300, error=0.005\n",
      ">epoch=393, lrate=0.300, error=0.005\n",
      ">epoch=394, lrate=0.300, error=0.005\n",
      ">epoch=395, lrate=0.300, error=0.005\n",
      ">epoch=396, lrate=0.300, error=0.005\n",
      ">epoch=397, lrate=0.300, error=0.005\n",
      ">epoch=398, lrate=0.300, error=0.005\n",
      ">epoch=399, lrate=0.300, error=0.005\n",
      ">epoch=400, lrate=0.300, error=0.005\n",
      ">epoch=401, lrate=0.300, error=0.005\n",
      ">epoch=402, lrate=0.300, error=0.005\n",
      ">epoch=403, lrate=0.300, error=0.005\n",
      ">epoch=404, lrate=0.300, error=0.005\n",
      ">epoch=405, lrate=0.300, error=0.005\n",
      ">epoch=406, lrate=0.300, error=0.005\n",
      ">epoch=407, lrate=0.300, error=0.005\n",
      ">epoch=408, lrate=0.300, error=0.005\n",
      ">epoch=409, lrate=0.300, error=0.005\n",
      ">epoch=410, lrate=0.300, error=0.005\n",
      ">epoch=411, lrate=0.300, error=0.005\n",
      ">epoch=412, lrate=0.300, error=0.005\n",
      ">epoch=413, lrate=0.300, error=0.005\n",
      ">epoch=414, lrate=0.300, error=0.005\n",
      ">epoch=415, lrate=0.300, error=0.005\n",
      ">epoch=416, lrate=0.300, error=0.005\n",
      ">epoch=417, lrate=0.300, error=0.005\n",
      ">epoch=418, lrate=0.300, error=0.005\n",
      ">epoch=419, lrate=0.300, error=0.005\n",
      ">epoch=420, lrate=0.300, error=0.005\n",
      ">epoch=421, lrate=0.300, error=0.005\n",
      ">epoch=422, lrate=0.300, error=0.005\n",
      ">epoch=423, lrate=0.300, error=0.005\n",
      ">epoch=424, lrate=0.300, error=0.005\n",
      ">epoch=425, lrate=0.300, error=0.005\n",
      ">epoch=426, lrate=0.300, error=0.005\n",
      ">epoch=427, lrate=0.300, error=0.005\n",
      ">epoch=428, lrate=0.300, error=0.005\n",
      ">epoch=429, lrate=0.300, error=0.005\n",
      ">epoch=430, lrate=0.300, error=0.005\n",
      ">epoch=431, lrate=0.300, error=0.005\n",
      ">epoch=432, lrate=0.300, error=0.005\n",
      ">epoch=433, lrate=0.300, error=0.005\n",
      ">epoch=434, lrate=0.300, error=0.005\n",
      ">epoch=435, lrate=0.300, error=0.005\n",
      ">epoch=436, lrate=0.300, error=0.005\n",
      ">epoch=437, lrate=0.300, error=0.005\n",
      ">epoch=438, lrate=0.300, error=0.005\n",
      ">epoch=439, lrate=0.300, error=0.005\n",
      ">epoch=440, lrate=0.300, error=0.005\n",
      ">epoch=441, lrate=0.300, error=0.005\n",
      ">epoch=442, lrate=0.300, error=0.005\n",
      ">epoch=443, lrate=0.300, error=0.005\n",
      ">epoch=444, lrate=0.300, error=0.005\n",
      ">epoch=445, lrate=0.300, error=0.005\n",
      ">epoch=446, lrate=0.300, error=0.005\n",
      ">epoch=447, lrate=0.300, error=0.005\n",
      ">epoch=448, lrate=0.300, error=0.005\n",
      ">epoch=449, lrate=0.300, error=0.005\n",
      ">epoch=450, lrate=0.300, error=0.005\n",
      ">epoch=451, lrate=0.300, error=0.005\n",
      ">epoch=452, lrate=0.300, error=0.005\n",
      ">epoch=453, lrate=0.300, error=0.005\n",
      ">epoch=454, lrate=0.300, error=0.005\n",
      ">epoch=455, lrate=0.300, error=0.005\n",
      ">epoch=456, lrate=0.300, error=0.005\n",
      ">epoch=457, lrate=0.300, error=0.005\n",
      ">epoch=458, lrate=0.300, error=0.005\n",
      ">epoch=459, lrate=0.300, error=0.005\n",
      ">epoch=460, lrate=0.300, error=0.005\n",
      ">epoch=461, lrate=0.300, error=0.005\n",
      ">epoch=462, lrate=0.300, error=0.005\n",
      ">epoch=463, lrate=0.300, error=0.005\n",
      ">epoch=464, lrate=0.300, error=0.005\n",
      ">epoch=465, lrate=0.300, error=0.005\n",
      ">epoch=466, lrate=0.300, error=0.005\n",
      ">epoch=467, lrate=0.300, error=0.005\n",
      ">epoch=468, lrate=0.300, error=0.005\n",
      ">epoch=469, lrate=0.300, error=0.005\n",
      ">epoch=470, lrate=0.300, error=0.005\n",
      ">epoch=471, lrate=0.300, error=0.005\n",
      ">epoch=472, lrate=0.300, error=0.005\n",
      ">epoch=473, lrate=0.300, error=0.005\n",
      ">epoch=474, lrate=0.300, error=0.005\n",
      ">epoch=475, lrate=0.300, error=0.005\n",
      ">epoch=476, lrate=0.300, error=0.005\n",
      ">epoch=477, lrate=0.300, error=0.005\n",
      ">epoch=478, lrate=0.300, error=0.004\n",
      ">epoch=479, lrate=0.300, error=0.004\n",
      ">epoch=480, lrate=0.300, error=0.004\n",
      ">epoch=481, lrate=0.300, error=0.004\n",
      ">epoch=482, lrate=0.300, error=0.004\n",
      ">epoch=483, lrate=0.300, error=0.004\n",
      ">epoch=484, lrate=0.300, error=0.004\n",
      ">epoch=485, lrate=0.300, error=0.004\n",
      ">epoch=486, lrate=0.300, error=0.004\n",
      ">epoch=487, lrate=0.300, error=0.004\n",
      ">epoch=488, lrate=0.300, error=0.004\n",
      ">epoch=489, lrate=0.300, error=0.004\n",
      ">epoch=490, lrate=0.300, error=0.004\n",
      ">epoch=491, lrate=0.300, error=0.004\n",
      ">epoch=492, lrate=0.300, error=0.004\n",
      ">epoch=493, lrate=0.300, error=0.004\n",
      ">epoch=494, lrate=0.300, error=0.004\n",
      ">epoch=495, lrate=0.300, error=0.004\n",
      ">epoch=496, lrate=0.300, error=0.004\n",
      ">epoch=497, lrate=0.300, error=0.004\n",
      ">epoch=498, lrate=0.300, error=0.004\n",
      ">epoch=499, lrate=0.300, error=0.004\n",
      ">epoch=500, lrate=0.300, error=0.004\n",
      ">epoch=501, lrate=0.300, error=0.004\n",
      ">epoch=502, lrate=0.300, error=0.004\n",
      ">epoch=503, lrate=0.300, error=0.004\n",
      ">epoch=504, lrate=0.300, error=0.004\n",
      ">epoch=505, lrate=0.300, error=0.004\n",
      ">epoch=506, lrate=0.300, error=0.004\n",
      ">epoch=507, lrate=0.300, error=0.004\n",
      ">epoch=508, lrate=0.300, error=0.004\n",
      ">epoch=509, lrate=0.300, error=0.004\n",
      ">epoch=510, lrate=0.300, error=0.004\n",
      ">epoch=511, lrate=0.300, error=0.004\n",
      ">epoch=512, lrate=0.300, error=0.004\n",
      ">epoch=513, lrate=0.300, error=0.004\n",
      ">epoch=514, lrate=0.300, error=0.004\n",
      ">epoch=515, lrate=0.300, error=0.004\n",
      ">epoch=516, lrate=0.300, error=0.004\n",
      ">epoch=517, lrate=0.300, error=0.004\n",
      ">epoch=518, lrate=0.300, error=0.004\n",
      ">epoch=519, lrate=0.300, error=0.004\n",
      ">epoch=520, lrate=0.300, error=0.004\n",
      ">epoch=521, lrate=0.300, error=0.004\n",
      ">epoch=522, lrate=0.300, error=0.004\n",
      ">epoch=523, lrate=0.300, error=0.004\n",
      ">epoch=524, lrate=0.300, error=0.004\n",
      ">epoch=525, lrate=0.300, error=0.004\n",
      ">epoch=526, lrate=0.300, error=0.004\n",
      ">epoch=527, lrate=0.300, error=0.004\n",
      ">epoch=528, lrate=0.300, error=0.004\n",
      ">epoch=529, lrate=0.300, error=0.004\n",
      ">epoch=530, lrate=0.300, error=0.004\n",
      ">epoch=531, lrate=0.300, error=0.004\n",
      ">epoch=532, lrate=0.300, error=0.004\n",
      ">epoch=533, lrate=0.300, error=0.004\n",
      ">epoch=534, lrate=0.300, error=0.004\n",
      ">epoch=535, lrate=0.300, error=0.004\n",
      ">epoch=536, lrate=0.300, error=0.004\n",
      ">epoch=537, lrate=0.300, error=0.004\n",
      ">epoch=538, lrate=0.300, error=0.004\n",
      ">epoch=539, lrate=0.300, error=0.004\n",
      ">epoch=540, lrate=0.300, error=0.004\n",
      ">epoch=541, lrate=0.300, error=0.004\n",
      ">epoch=542, lrate=0.300, error=0.004\n",
      ">epoch=543, lrate=0.300, error=0.004\n",
      ">epoch=544, lrate=0.300, error=0.004\n",
      ">epoch=545, lrate=0.300, error=0.004\n",
      ">epoch=546, lrate=0.300, error=0.004\n",
      ">epoch=547, lrate=0.300, error=0.004\n",
      ">epoch=548, lrate=0.300, error=0.004\n",
      ">epoch=549, lrate=0.300, error=0.004\n",
      ">epoch=550, lrate=0.300, error=0.004\n",
      ">epoch=551, lrate=0.300, error=0.004\n",
      ">epoch=552, lrate=0.300, error=0.004\n",
      ">epoch=553, lrate=0.300, error=0.004\n",
      ">epoch=554, lrate=0.300, error=0.004\n",
      ">epoch=555, lrate=0.300, error=0.004\n",
      ">epoch=556, lrate=0.300, error=0.004\n",
      ">epoch=557, lrate=0.300, error=0.004\n",
      ">epoch=558, lrate=0.300, error=0.004\n",
      ">epoch=559, lrate=0.300, error=0.004\n",
      ">epoch=560, lrate=0.300, error=0.004\n",
      ">epoch=561, lrate=0.300, error=0.004\n",
      ">epoch=562, lrate=0.300, error=0.004\n",
      ">epoch=563, lrate=0.300, error=0.004\n",
      ">epoch=564, lrate=0.300, error=0.004\n",
      ">epoch=565, lrate=0.300, error=0.004\n",
      ">epoch=566, lrate=0.300, error=0.004\n",
      ">epoch=567, lrate=0.300, error=0.004\n",
      ">epoch=568, lrate=0.300, error=0.004\n",
      ">epoch=569, lrate=0.300, error=0.004\n",
      ">epoch=570, lrate=0.300, error=0.004\n",
      ">epoch=571, lrate=0.300, error=0.004\n",
      ">epoch=572, lrate=0.300, error=0.004\n",
      ">epoch=573, lrate=0.300, error=0.004\n",
      ">epoch=574, lrate=0.300, error=0.004\n",
      ">epoch=575, lrate=0.300, error=0.004\n",
      ">epoch=576, lrate=0.300, error=0.004\n",
      ">epoch=577, lrate=0.300, error=0.004\n",
      ">epoch=578, lrate=0.300, error=0.004\n",
      ">epoch=579, lrate=0.300, error=0.004\n",
      ">epoch=580, lrate=0.300, error=0.004\n",
      ">epoch=581, lrate=0.300, error=0.004\n",
      ">epoch=582, lrate=0.300, error=0.004\n",
      ">epoch=583, lrate=0.300, error=0.004\n",
      ">epoch=584, lrate=0.300, error=0.004\n",
      ">epoch=585, lrate=0.300, error=0.004\n",
      ">epoch=586, lrate=0.300, error=0.004\n",
      ">epoch=587, lrate=0.300, error=0.004\n",
      ">epoch=588, lrate=0.300, error=0.004\n",
      ">epoch=589, lrate=0.300, error=0.004\n",
      ">epoch=590, lrate=0.300, error=0.004\n",
      ">epoch=591, lrate=0.300, error=0.004\n",
      ">epoch=592, lrate=0.300, error=0.004\n",
      ">epoch=593, lrate=0.300, error=0.004\n",
      ">epoch=594, lrate=0.300, error=0.004\n",
      ">epoch=595, lrate=0.300, error=0.004\n",
      ">epoch=596, lrate=0.300, error=0.004\n",
      ">epoch=597, lrate=0.300, error=0.004\n",
      ">epoch=598, lrate=0.300, error=0.004\n",
      ">epoch=599, lrate=0.300, error=0.004\n",
      ">epoch=600, lrate=0.300, error=0.004\n",
      ">epoch=601, lrate=0.300, error=0.004\n",
      ">epoch=602, lrate=0.300, error=0.004\n",
      ">epoch=603, lrate=0.300, error=0.004\n",
      ">epoch=604, lrate=0.300, error=0.004\n",
      ">epoch=605, lrate=0.300, error=0.004\n",
      ">epoch=606, lrate=0.300, error=0.004\n",
      ">epoch=607, lrate=0.300, error=0.004\n",
      ">epoch=608, lrate=0.300, error=0.004\n",
      ">epoch=609, lrate=0.300, error=0.004\n",
      ">epoch=610, lrate=0.300, error=0.004\n",
      ">epoch=611, lrate=0.300, error=0.004\n",
      ">epoch=612, lrate=0.300, error=0.004\n",
      ">epoch=613, lrate=0.300, error=0.003\n",
      ">epoch=614, lrate=0.300, error=0.003\n",
      ">epoch=615, lrate=0.300, error=0.003\n",
      ">epoch=616, lrate=0.300, error=0.003\n",
      ">epoch=617, lrate=0.300, error=0.003\n",
      ">epoch=618, lrate=0.300, error=0.003\n",
      ">epoch=619, lrate=0.300, error=0.003\n",
      ">epoch=620, lrate=0.300, error=0.003\n",
      ">epoch=621, lrate=0.300, error=0.003\n",
      ">epoch=622, lrate=0.300, error=0.003\n",
      ">epoch=623, lrate=0.300, error=0.003\n",
      ">epoch=624, lrate=0.300, error=0.003\n",
      ">epoch=625, lrate=0.300, error=0.003\n",
      ">epoch=626, lrate=0.300, error=0.003\n",
      ">epoch=627, lrate=0.300, error=0.003\n",
      ">epoch=628, lrate=0.300, error=0.003\n",
      ">epoch=629, lrate=0.300, error=0.003\n",
      ">epoch=630, lrate=0.300, error=0.003\n",
      ">epoch=631, lrate=0.300, error=0.003\n",
      ">epoch=632, lrate=0.300, error=0.003\n",
      ">epoch=633, lrate=0.300, error=0.003\n",
      ">epoch=634, lrate=0.300, error=0.003\n",
      ">epoch=635, lrate=0.300, error=0.003\n",
      ">epoch=636, lrate=0.300, error=0.003\n",
      ">epoch=637, lrate=0.300, error=0.003\n",
      ">epoch=638, lrate=0.300, error=0.003\n",
      ">epoch=639, lrate=0.300, error=0.003\n",
      ">epoch=640, lrate=0.300, error=0.003\n",
      ">epoch=641, lrate=0.300, error=0.003\n",
      ">epoch=642, lrate=0.300, error=0.003\n",
      ">epoch=643, lrate=0.300, error=0.003\n",
      ">epoch=644, lrate=0.300, error=0.003\n",
      ">epoch=645, lrate=0.300, error=0.003\n",
      ">epoch=646, lrate=0.300, error=0.003\n",
      ">epoch=647, lrate=0.300, error=0.003\n",
      ">epoch=648, lrate=0.300, error=0.003\n",
      ">epoch=649, lrate=0.300, error=0.003\n",
      ">epoch=650, lrate=0.300, error=0.003\n",
      ">epoch=651, lrate=0.300, error=0.003\n",
      ">epoch=652, lrate=0.300, error=0.003\n",
      ">epoch=653, lrate=0.300, error=0.003\n",
      ">epoch=654, lrate=0.300, error=0.003\n",
      ">epoch=655, lrate=0.300, error=0.003\n",
      ">epoch=656, lrate=0.300, error=0.003\n",
      ">epoch=657, lrate=0.300, error=0.003\n",
      ">epoch=658, lrate=0.300, error=0.003\n",
      ">epoch=659, lrate=0.300, error=0.003\n",
      ">epoch=660, lrate=0.300, error=0.003\n",
      ">epoch=661, lrate=0.300, error=0.003\n",
      ">epoch=662, lrate=0.300, error=0.003\n",
      ">epoch=663, lrate=0.300, error=0.003\n",
      ">epoch=664, lrate=0.300, error=0.003\n",
      ">epoch=665, lrate=0.300, error=0.003\n",
      ">epoch=666, lrate=0.300, error=0.003\n",
      ">epoch=667, lrate=0.300, error=0.003\n",
      ">epoch=668, lrate=0.300, error=0.003\n",
      ">epoch=669, lrate=0.300, error=0.003\n",
      ">epoch=670, lrate=0.300, error=0.003\n",
      ">epoch=671, lrate=0.300, error=0.003\n",
      ">epoch=672, lrate=0.300, error=0.003\n",
      ">epoch=673, lrate=0.300, error=0.003\n",
      ">epoch=674, lrate=0.300, error=0.003\n",
      ">epoch=675, lrate=0.300, error=0.003\n",
      ">epoch=676, lrate=0.300, error=0.003\n",
      ">epoch=677, lrate=0.300, error=0.003\n",
      ">epoch=678, lrate=0.300, error=0.003\n",
      ">epoch=679, lrate=0.300, error=0.003\n",
      ">epoch=680, lrate=0.300, error=0.003\n",
      ">epoch=681, lrate=0.300, error=0.003\n",
      ">epoch=682, lrate=0.300, error=0.003\n",
      ">epoch=683, lrate=0.300, error=0.003\n",
      ">epoch=684, lrate=0.300, error=0.003\n",
      ">epoch=685, lrate=0.300, error=0.003\n",
      ">epoch=686, lrate=0.300, error=0.003\n",
      ">epoch=687, lrate=0.300, error=0.003\n",
      ">epoch=688, lrate=0.300, error=0.003\n",
      ">epoch=689, lrate=0.300, error=0.003\n",
      ">epoch=690, lrate=0.300, error=0.003\n",
      ">epoch=691, lrate=0.300, error=0.003\n",
      ">epoch=692, lrate=0.300, error=0.003\n",
      ">epoch=693, lrate=0.300, error=0.003\n",
      ">epoch=694, lrate=0.300, error=0.003\n",
      ">epoch=695, lrate=0.300, error=0.003\n",
      ">epoch=696, lrate=0.300, error=0.003\n",
      ">epoch=697, lrate=0.300, error=0.003\n",
      ">epoch=698, lrate=0.300, error=0.003\n",
      ">epoch=699, lrate=0.300, error=0.003\n",
      ">epoch=700, lrate=0.300, error=0.003\n",
      ">epoch=701, lrate=0.300, error=0.003\n",
      ">epoch=702, lrate=0.300, error=0.003\n",
      ">epoch=703, lrate=0.300, error=0.003\n",
      ">epoch=704, lrate=0.300, error=0.003\n",
      ">epoch=705, lrate=0.300, error=0.003\n",
      ">epoch=706, lrate=0.300, error=0.003\n",
      ">epoch=707, lrate=0.300, error=0.003\n",
      ">epoch=708, lrate=0.300, error=0.003\n",
      ">epoch=709, lrate=0.300, error=0.003\n",
      ">epoch=710, lrate=0.300, error=0.003\n",
      ">epoch=711, lrate=0.300, error=0.003\n",
      ">epoch=712, lrate=0.300, error=0.003\n",
      ">epoch=713, lrate=0.300, error=0.003\n",
      ">epoch=714, lrate=0.300, error=0.003\n",
      ">epoch=715, lrate=0.300, error=0.003\n",
      ">epoch=716, lrate=0.300, error=0.003\n",
      ">epoch=717, lrate=0.300, error=0.003\n",
      ">epoch=718, lrate=0.300, error=0.003\n",
      ">epoch=719, lrate=0.300, error=0.003\n",
      ">epoch=720, lrate=0.300, error=0.003\n",
      ">epoch=721, lrate=0.300, error=0.003\n",
      ">epoch=722, lrate=0.300, error=0.003\n",
      ">epoch=723, lrate=0.300, error=0.003\n",
      ">epoch=724, lrate=0.300, error=0.003\n",
      ">epoch=725, lrate=0.300, error=0.003\n",
      ">epoch=726, lrate=0.300, error=0.003\n",
      ">epoch=727, lrate=0.300, error=0.003\n",
      ">epoch=728, lrate=0.300, error=0.003\n",
      ">epoch=729, lrate=0.300, error=0.003\n",
      ">epoch=730, lrate=0.300, error=0.003\n",
      ">epoch=731, lrate=0.300, error=0.003\n",
      ">epoch=732, lrate=0.300, error=0.003\n",
      ">epoch=733, lrate=0.300, error=0.003\n",
      ">epoch=734, lrate=0.300, error=0.003\n",
      ">epoch=735, lrate=0.300, error=0.003\n",
      ">epoch=736, lrate=0.300, error=0.003\n",
      ">epoch=737, lrate=0.300, error=0.003\n",
      ">epoch=738, lrate=0.300, error=0.003\n",
      ">epoch=739, lrate=0.300, error=0.003\n",
      ">epoch=740, lrate=0.300, error=0.003\n",
      ">epoch=741, lrate=0.300, error=0.003\n",
      ">epoch=742, lrate=0.300, error=0.003\n",
      ">epoch=743, lrate=0.300, error=0.003\n",
      ">epoch=744, lrate=0.300, error=0.003\n",
      ">epoch=745, lrate=0.300, error=0.003\n",
      ">epoch=746, lrate=0.300, error=0.003\n",
      ">epoch=747, lrate=0.300, error=0.003\n",
      ">epoch=748, lrate=0.300, error=0.003\n",
      ">epoch=749, lrate=0.300, error=0.003\n",
      ">epoch=750, lrate=0.300, error=0.003\n",
      ">epoch=751, lrate=0.300, error=0.003\n",
      ">epoch=752, lrate=0.300, error=0.003\n",
      ">epoch=753, lrate=0.300, error=0.003\n",
      ">epoch=754, lrate=0.300, error=0.003\n",
      ">epoch=755, lrate=0.300, error=0.003\n",
      ">epoch=756, lrate=0.300, error=0.003\n",
      ">epoch=757, lrate=0.300, error=0.003\n",
      ">epoch=758, lrate=0.300, error=0.003\n",
      ">epoch=759, lrate=0.300, error=0.003\n",
      ">epoch=760, lrate=0.300, error=0.003\n",
      ">epoch=761, lrate=0.300, error=0.003\n",
      ">epoch=762, lrate=0.300, error=0.003\n",
      ">epoch=763, lrate=0.300, error=0.003\n",
      ">epoch=764, lrate=0.300, error=0.003\n",
      ">epoch=765, lrate=0.300, error=0.003\n",
      ">epoch=766, lrate=0.300, error=0.003\n",
      ">epoch=767, lrate=0.300, error=0.003\n",
      ">epoch=768, lrate=0.300, error=0.003\n",
      ">epoch=769, lrate=0.300, error=0.003\n",
      ">epoch=770, lrate=0.300, error=0.003\n",
      ">epoch=771, lrate=0.300, error=0.003\n",
      ">epoch=772, lrate=0.300, error=0.003\n",
      ">epoch=773, lrate=0.300, error=0.003\n",
      ">epoch=774, lrate=0.300, error=0.003\n",
      ">epoch=775, lrate=0.300, error=0.003\n",
      ">epoch=776, lrate=0.300, error=0.003\n",
      ">epoch=777, lrate=0.300, error=0.003\n",
      ">epoch=778, lrate=0.300, error=0.003\n",
      ">epoch=779, lrate=0.300, error=0.003\n",
      ">epoch=780, lrate=0.300, error=0.003\n",
      ">epoch=781, lrate=0.300, error=0.003\n",
      ">epoch=782, lrate=0.300, error=0.003\n",
      ">epoch=783, lrate=0.300, error=0.003\n",
      ">epoch=784, lrate=0.300, error=0.003\n",
      ">epoch=785, lrate=0.300, error=0.003\n",
      ">epoch=786, lrate=0.300, error=0.003\n",
      ">epoch=787, lrate=0.300, error=0.003\n",
      ">epoch=788, lrate=0.300, error=0.003\n",
      ">epoch=789, lrate=0.300, error=0.003\n",
      ">epoch=790, lrate=0.300, error=0.003\n",
      ">epoch=791, lrate=0.300, error=0.003\n",
      ">epoch=792, lrate=0.300, error=0.003\n",
      ">epoch=793, lrate=0.300, error=0.003\n",
      ">epoch=794, lrate=0.300, error=0.003\n",
      ">epoch=795, lrate=0.300, error=0.003\n",
      ">epoch=796, lrate=0.300, error=0.003\n",
      ">epoch=797, lrate=0.300, error=0.003\n",
      ">epoch=798, lrate=0.300, error=0.003\n",
      ">epoch=799, lrate=0.300, error=0.003\n",
      ">epoch=800, lrate=0.300, error=0.003\n",
      ">epoch=801, lrate=0.300, error=0.003\n",
      ">epoch=802, lrate=0.300, error=0.003\n",
      ">epoch=803, lrate=0.300, error=0.003\n",
      ">epoch=804, lrate=0.300, error=0.003\n",
      ">epoch=805, lrate=0.300, error=0.003\n",
      ">epoch=806, lrate=0.300, error=0.003\n",
      ">epoch=807, lrate=0.300, error=0.003\n",
      ">epoch=808, lrate=0.300, error=0.003\n",
      ">epoch=809, lrate=0.300, error=0.003\n",
      ">epoch=810, lrate=0.300, error=0.003\n",
      ">epoch=811, lrate=0.300, error=0.003\n",
      ">epoch=812, lrate=0.300, error=0.003\n",
      ">epoch=813, lrate=0.300, error=0.003\n",
      ">epoch=814, lrate=0.300, error=0.003\n",
      ">epoch=815, lrate=0.300, error=0.003\n",
      ">epoch=816, lrate=0.300, error=0.003\n",
      ">epoch=817, lrate=0.300, error=0.003\n",
      ">epoch=818, lrate=0.300, error=0.003\n",
      ">epoch=819, lrate=0.300, error=0.003\n",
      ">epoch=820, lrate=0.300, error=0.003\n",
      ">epoch=821, lrate=0.300, error=0.003\n",
      ">epoch=822, lrate=0.300, error=0.003\n",
      ">epoch=823, lrate=0.300, error=0.003\n",
      ">epoch=824, lrate=0.300, error=0.003\n",
      ">epoch=825, lrate=0.300, error=0.003\n",
      ">epoch=826, lrate=0.300, error=0.003\n",
      ">epoch=827, lrate=0.300, error=0.003\n",
      ">epoch=828, lrate=0.300, error=0.003\n",
      ">epoch=829, lrate=0.300, error=0.003\n",
      ">epoch=830, lrate=0.300, error=0.003\n",
      ">epoch=831, lrate=0.300, error=0.003\n",
      ">epoch=832, lrate=0.300, error=0.003\n",
      ">epoch=833, lrate=0.300, error=0.003\n",
      ">epoch=834, lrate=0.300, error=0.003\n",
      ">epoch=835, lrate=0.300, error=0.003\n",
      ">epoch=836, lrate=0.300, error=0.003\n",
      ">epoch=837, lrate=0.300, error=0.003\n",
      ">epoch=838, lrate=0.300, error=0.003\n",
      ">epoch=839, lrate=0.300, error=0.003\n",
      ">epoch=840, lrate=0.300, error=0.003\n",
      ">epoch=841, lrate=0.300, error=0.003\n",
      ">epoch=842, lrate=0.300, error=0.003\n",
      ">epoch=843, lrate=0.300, error=0.003\n",
      ">epoch=844, lrate=0.300, error=0.003\n",
      ">epoch=845, lrate=0.300, error=0.003\n",
      ">epoch=846, lrate=0.300, error=0.003\n",
      ">epoch=847, lrate=0.300, error=0.003\n",
      ">epoch=848, lrate=0.300, error=0.003\n",
      ">epoch=849, lrate=0.300, error=0.003\n",
      ">epoch=850, lrate=0.300, error=0.003\n",
      ">epoch=851, lrate=0.300, error=0.003\n",
      ">epoch=852, lrate=0.300, error=0.003\n",
      ">epoch=853, lrate=0.300, error=0.003\n",
      ">epoch=854, lrate=0.300, error=0.003\n",
      ">epoch=855, lrate=0.300, error=0.003\n",
      ">epoch=856, lrate=0.300, error=0.002\n",
      ">epoch=857, lrate=0.300, error=0.002\n",
      ">epoch=858, lrate=0.300, error=0.002\n",
      ">epoch=859, lrate=0.300, error=0.002\n",
      ">epoch=860, lrate=0.300, error=0.002\n",
      ">epoch=861, lrate=0.300, error=0.002\n",
      ">epoch=862, lrate=0.300, error=0.002\n",
      ">epoch=863, lrate=0.300, error=0.002\n",
      ">epoch=864, lrate=0.300, error=0.002\n",
      ">epoch=865, lrate=0.300, error=0.002\n",
      ">epoch=866, lrate=0.300, error=0.002\n",
      ">epoch=867, lrate=0.300, error=0.002\n",
      ">epoch=868, lrate=0.300, error=0.002\n",
      ">epoch=869, lrate=0.300, error=0.002\n",
      ">epoch=870, lrate=0.300, error=0.002\n",
      ">epoch=871, lrate=0.300, error=0.002\n",
      ">epoch=872, lrate=0.300, error=0.002\n",
      ">epoch=873, lrate=0.300, error=0.002\n",
      ">epoch=874, lrate=0.300, error=0.002\n",
      ">epoch=875, lrate=0.300, error=0.002\n",
      ">epoch=876, lrate=0.300, error=0.002\n",
      ">epoch=877, lrate=0.300, error=0.002\n",
      ">epoch=878, lrate=0.300, error=0.002\n",
      ">epoch=879, lrate=0.300, error=0.002\n",
      ">epoch=880, lrate=0.300, error=0.002\n",
      ">epoch=881, lrate=0.300, error=0.002\n",
      ">epoch=882, lrate=0.300, error=0.002\n",
      ">epoch=883, lrate=0.300, error=0.002\n",
      ">epoch=884, lrate=0.300, error=0.002\n",
      ">epoch=885, lrate=0.300, error=0.002\n",
      ">epoch=886, lrate=0.300, error=0.002\n",
      ">epoch=887, lrate=0.300, error=0.002\n",
      ">epoch=888, lrate=0.300, error=0.002\n",
      ">epoch=889, lrate=0.300, error=0.002\n",
      ">epoch=890, lrate=0.300, error=0.002\n",
      ">epoch=891, lrate=0.300, error=0.002\n",
      ">epoch=892, lrate=0.300, error=0.002\n",
      ">epoch=893, lrate=0.300, error=0.002\n",
      ">epoch=894, lrate=0.300, error=0.002\n",
      ">epoch=895, lrate=0.300, error=0.002\n",
      ">epoch=896, lrate=0.300, error=0.002\n",
      ">epoch=897, lrate=0.300, error=0.002\n",
      ">epoch=898, lrate=0.300, error=0.002\n",
      ">epoch=899, lrate=0.300, error=0.002\n",
      ">epoch=900, lrate=0.300, error=0.002\n",
      ">epoch=901, lrate=0.300, error=0.002\n",
      ">epoch=902, lrate=0.300, error=0.002\n",
      ">epoch=903, lrate=0.300, error=0.002\n",
      ">epoch=904, lrate=0.300, error=0.002\n",
      ">epoch=905, lrate=0.300, error=0.002\n",
      ">epoch=906, lrate=0.300, error=0.002\n",
      ">epoch=907, lrate=0.300, error=0.002\n",
      ">epoch=908, lrate=0.300, error=0.002\n",
      ">epoch=909, lrate=0.300, error=0.002\n",
      ">epoch=910, lrate=0.300, error=0.002\n",
      ">epoch=911, lrate=0.300, error=0.002\n",
      ">epoch=912, lrate=0.300, error=0.002\n",
      ">epoch=913, lrate=0.300, error=0.002\n",
      ">epoch=914, lrate=0.300, error=0.002\n",
      ">epoch=915, lrate=0.300, error=0.002\n",
      ">epoch=916, lrate=0.300, error=0.002\n",
      ">epoch=917, lrate=0.300, error=0.002\n",
      ">epoch=918, lrate=0.300, error=0.002\n",
      ">epoch=919, lrate=0.300, error=0.002\n",
      ">epoch=920, lrate=0.300, error=0.002\n",
      ">epoch=921, lrate=0.300, error=0.002\n",
      ">epoch=922, lrate=0.300, error=0.002\n",
      ">epoch=923, lrate=0.300, error=0.002\n",
      ">epoch=924, lrate=0.300, error=0.002\n",
      ">epoch=925, lrate=0.300, error=0.002\n",
      ">epoch=926, lrate=0.300, error=0.002\n",
      ">epoch=927, lrate=0.300, error=0.002\n",
      ">epoch=928, lrate=0.300, error=0.002\n",
      ">epoch=929, lrate=0.300, error=0.002\n",
      ">epoch=930, lrate=0.300, error=0.002\n",
      ">epoch=931, lrate=0.300, error=0.002\n",
      ">epoch=932, lrate=0.300, error=0.002\n",
      ">epoch=933, lrate=0.300, error=0.002\n",
      ">epoch=934, lrate=0.300, error=0.002\n",
      ">epoch=935, lrate=0.300, error=0.002\n",
      ">epoch=936, lrate=0.300, error=0.002\n",
      ">epoch=937, lrate=0.300, error=0.002\n",
      ">epoch=938, lrate=0.300, error=0.002\n",
      ">epoch=939, lrate=0.300, error=0.002\n",
      ">epoch=940, lrate=0.300, error=0.002\n",
      ">epoch=941, lrate=0.300, error=0.002\n",
      ">epoch=942, lrate=0.300, error=0.002\n",
      ">epoch=943, lrate=0.300, error=0.002\n",
      ">epoch=944, lrate=0.300, error=0.002\n",
      ">epoch=945, lrate=0.300, error=0.002\n",
      ">epoch=946, lrate=0.300, error=0.002\n",
      ">epoch=947, lrate=0.300, error=0.002\n",
      ">epoch=948, lrate=0.300, error=0.002\n",
      ">epoch=949, lrate=0.300, error=0.002\n",
      ">epoch=950, lrate=0.300, error=0.002\n",
      ">epoch=951, lrate=0.300, error=0.002\n",
      ">epoch=952, lrate=0.300, error=0.002\n",
      ">epoch=953, lrate=0.300, error=0.002\n",
      ">epoch=954, lrate=0.300, error=0.002\n",
      ">epoch=955, lrate=0.300, error=0.002\n",
      ">epoch=956, lrate=0.300, error=0.002\n",
      ">epoch=957, lrate=0.300, error=0.002\n",
      ">epoch=958, lrate=0.300, error=0.002\n",
      ">epoch=959, lrate=0.300, error=0.002\n",
      ">epoch=960, lrate=0.300, error=0.002\n",
      ">epoch=961, lrate=0.300, error=0.002\n",
      ">epoch=962, lrate=0.300, error=0.002\n",
      ">epoch=963, lrate=0.300, error=0.002\n",
      ">epoch=964, lrate=0.300, error=0.002\n",
      ">epoch=965, lrate=0.300, error=0.002\n",
      ">epoch=966, lrate=0.300, error=0.002\n",
      ">epoch=967, lrate=0.300, error=0.002\n",
      ">epoch=968, lrate=0.300, error=0.002\n",
      ">epoch=969, lrate=0.300, error=0.002\n",
      ">epoch=970, lrate=0.300, error=0.002\n",
      ">epoch=971, lrate=0.300, error=0.002\n",
      ">epoch=972, lrate=0.300, error=0.002\n",
      ">epoch=973, lrate=0.300, error=0.002\n",
      ">epoch=974, lrate=0.300, error=0.002\n",
      ">epoch=975, lrate=0.300, error=0.002\n",
      ">epoch=976, lrate=0.300, error=0.002\n",
      ">epoch=977, lrate=0.300, error=0.002\n",
      ">epoch=978, lrate=0.300, error=0.002\n",
      ">epoch=979, lrate=0.300, error=0.002\n",
      ">epoch=980, lrate=0.300, error=0.002\n",
      ">epoch=981, lrate=0.300, error=0.002\n",
      ">epoch=982, lrate=0.300, error=0.002\n",
      ">epoch=983, lrate=0.300, error=0.002\n",
      ">epoch=984, lrate=0.300, error=0.002\n",
      ">epoch=985, lrate=0.300, error=0.002\n",
      ">epoch=986, lrate=0.300, error=0.002\n",
      ">epoch=987, lrate=0.300, error=0.002\n",
      ">epoch=988, lrate=0.300, error=0.002\n",
      ">epoch=989, lrate=0.300, error=0.002\n",
      ">epoch=990, lrate=0.300, error=0.002\n",
      ">epoch=991, lrate=0.300, error=0.002\n",
      ">epoch=992, lrate=0.300, error=0.002\n",
      ">epoch=993, lrate=0.300, error=0.002\n",
      ">epoch=994, lrate=0.300, error=0.002\n",
      ">epoch=995, lrate=0.300, error=0.002\n",
      ">epoch=996, lrate=0.300, error=0.002\n",
      ">epoch=997, lrate=0.300, error=0.002\n",
      ">epoch=998, lrate=0.300, error=0.002\n",
      ">epoch=999, lrate=0.300, error=0.002\n",
      ">epoch=1000, lrate=0.300, error=0.002\n",
      ">epoch=1001, lrate=0.300, error=0.002\n",
      ">epoch=1002, lrate=0.300, error=0.002\n",
      ">epoch=1003, lrate=0.300, error=0.002\n",
      ">epoch=1004, lrate=0.300, error=0.002\n",
      ">epoch=1005, lrate=0.300, error=0.002\n",
      ">epoch=1006, lrate=0.300, error=0.002\n",
      ">epoch=1007, lrate=0.300, error=0.002\n",
      ">epoch=1008, lrate=0.300, error=0.002\n",
      ">epoch=1009, lrate=0.300, error=0.002\n",
      ">epoch=1010, lrate=0.300, error=0.002\n",
      ">epoch=1011, lrate=0.300, error=0.002\n",
      ">epoch=1012, lrate=0.300, error=0.002\n",
      ">epoch=1013, lrate=0.300, error=0.002\n",
      ">epoch=1014, lrate=0.300, error=0.002\n",
      ">epoch=1015, lrate=0.300, error=0.002\n",
      ">epoch=1016, lrate=0.300, error=0.002\n",
      ">epoch=1017, lrate=0.300, error=0.002\n",
      ">epoch=1018, lrate=0.300, error=0.002\n",
      ">epoch=1019, lrate=0.300, error=0.002\n",
      ">epoch=1020, lrate=0.300, error=0.002\n",
      ">epoch=1021, lrate=0.300, error=0.002\n",
      ">epoch=1022, lrate=0.300, error=0.002\n",
      ">epoch=1023, lrate=0.300, error=0.002\n",
      ">epoch=1024, lrate=0.300, error=0.002\n",
      ">epoch=1025, lrate=0.300, error=0.002\n",
      ">epoch=1026, lrate=0.300, error=0.002\n",
      ">epoch=1027, lrate=0.300, error=0.002\n",
      ">epoch=1028, lrate=0.300, error=0.002\n",
      ">epoch=1029, lrate=0.300, error=0.002\n",
      ">epoch=1030, lrate=0.300, error=0.002\n",
      ">epoch=1031, lrate=0.300, error=0.002\n",
      ">epoch=1032, lrate=0.300, error=0.002\n",
      ">epoch=1033, lrate=0.300, error=0.002\n",
      ">epoch=1034, lrate=0.300, error=0.002\n",
      ">epoch=1035, lrate=0.300, error=0.002\n",
      ">epoch=1036, lrate=0.300, error=0.002\n",
      ">epoch=1037, lrate=0.300, error=0.002\n",
      ">epoch=1038, lrate=0.300, error=0.002\n",
      ">epoch=1039, lrate=0.300, error=0.002\n",
      ">epoch=1040, lrate=0.300, error=0.002\n",
      ">epoch=1041, lrate=0.300, error=0.002\n",
      ">epoch=1042, lrate=0.300, error=0.002\n",
      ">epoch=1043, lrate=0.300, error=0.002\n",
      ">epoch=1044, lrate=0.300, error=0.002\n",
      ">epoch=1045, lrate=0.300, error=0.002\n",
      ">epoch=1046, lrate=0.300, error=0.002\n",
      ">epoch=1047, lrate=0.300, error=0.002\n",
      ">epoch=1048, lrate=0.300, error=0.002\n",
      ">epoch=1049, lrate=0.300, error=0.002\n",
      ">epoch=1050, lrate=0.300, error=0.002\n",
      ">epoch=1051, lrate=0.300, error=0.002\n",
      ">epoch=1052, lrate=0.300, error=0.002\n",
      ">epoch=1053, lrate=0.300, error=0.002\n",
      ">epoch=1054, lrate=0.300, error=0.002\n",
      ">epoch=1055, lrate=0.300, error=0.002\n",
      ">epoch=1056, lrate=0.300, error=0.002\n",
      ">epoch=1057, lrate=0.300, error=0.002\n",
      ">epoch=1058, lrate=0.300, error=0.002\n",
      ">epoch=1059, lrate=0.300, error=0.002\n",
      ">epoch=1060, lrate=0.300, error=0.002\n",
      ">epoch=1061, lrate=0.300, error=0.002\n",
      ">epoch=1062, lrate=0.300, error=0.002\n",
      ">epoch=1063, lrate=0.300, error=0.002\n",
      ">epoch=1064, lrate=0.300, error=0.002\n",
      ">epoch=1065, lrate=0.300, error=0.002\n",
      ">epoch=1066, lrate=0.300, error=0.002\n",
      ">epoch=1067, lrate=0.300, error=0.002\n",
      ">epoch=1068, lrate=0.300, error=0.002\n",
      ">epoch=1069, lrate=0.300, error=0.002\n",
      ">epoch=1070, lrate=0.300, error=0.002\n",
      ">epoch=1071, lrate=0.300, error=0.002\n",
      ">epoch=1072, lrate=0.300, error=0.002\n",
      ">epoch=1073, lrate=0.300, error=0.002\n",
      ">epoch=1074, lrate=0.300, error=0.002\n",
      ">epoch=1075, lrate=0.300, error=0.002\n",
      ">epoch=1076, lrate=0.300, error=0.002\n",
      ">epoch=1077, lrate=0.300, error=0.002\n",
      ">epoch=1078, lrate=0.300, error=0.002\n",
      ">epoch=1079, lrate=0.300, error=0.002\n",
      ">epoch=1080, lrate=0.300, error=0.002\n",
      ">epoch=1081, lrate=0.300, error=0.002\n",
      ">epoch=1082, lrate=0.300, error=0.002\n",
      ">epoch=1083, lrate=0.300, error=0.002\n",
      ">epoch=1084, lrate=0.300, error=0.002\n",
      ">epoch=1085, lrate=0.300, error=0.002\n",
      ">epoch=1086, lrate=0.300, error=0.002\n",
      ">epoch=1087, lrate=0.300, error=0.002\n",
      ">epoch=1088, lrate=0.300, error=0.002\n",
      ">epoch=1089, lrate=0.300, error=0.002\n",
      ">epoch=1090, lrate=0.300, error=0.002\n",
      ">epoch=1091, lrate=0.300, error=0.002\n",
      ">epoch=1092, lrate=0.300, error=0.002\n",
      ">epoch=1093, lrate=0.300, error=0.002\n",
      ">epoch=1094, lrate=0.300, error=0.002\n",
      ">epoch=1095, lrate=0.300, error=0.002\n",
      ">epoch=1096, lrate=0.300, error=0.002\n",
      ">epoch=1097, lrate=0.300, error=0.002\n",
      ">epoch=1098, lrate=0.300, error=0.002\n",
      ">epoch=1099, lrate=0.300, error=0.002\n",
      ">epoch=1100, lrate=0.300, error=0.002\n",
      ">epoch=1101, lrate=0.300, error=0.002\n",
      ">epoch=1102, lrate=0.300, error=0.002\n",
      ">epoch=1103, lrate=0.300, error=0.002\n",
      ">epoch=1104, lrate=0.300, error=0.002\n",
      ">epoch=1105, lrate=0.300, error=0.002\n",
      ">epoch=1106, lrate=0.300, error=0.002\n",
      ">epoch=1107, lrate=0.300, error=0.002\n",
      ">epoch=1108, lrate=0.300, error=0.002\n",
      ">epoch=1109, lrate=0.300, error=0.002\n",
      ">epoch=1110, lrate=0.300, error=0.002\n",
      ">epoch=1111, lrate=0.300, error=0.002\n",
      ">epoch=1112, lrate=0.300, error=0.002\n",
      ">epoch=1113, lrate=0.300, error=0.002\n",
      ">epoch=1114, lrate=0.300, error=0.002\n",
      ">epoch=1115, lrate=0.300, error=0.002\n",
      ">epoch=1116, lrate=0.300, error=0.002\n",
      ">epoch=1117, lrate=0.300, error=0.002\n",
      ">epoch=1118, lrate=0.300, error=0.002\n",
      ">epoch=1119, lrate=0.300, error=0.002\n",
      ">epoch=1120, lrate=0.300, error=0.002\n",
      ">epoch=1121, lrate=0.300, error=0.002\n",
      ">epoch=1122, lrate=0.300, error=0.002\n",
      ">epoch=1123, lrate=0.300, error=0.002\n",
      ">epoch=1124, lrate=0.300, error=0.002\n",
      ">epoch=1125, lrate=0.300, error=0.002\n",
      ">epoch=1126, lrate=0.300, error=0.002\n",
      ">epoch=1127, lrate=0.300, error=0.002\n",
      ">epoch=1128, lrate=0.300, error=0.002\n",
      ">epoch=1129, lrate=0.300, error=0.002\n",
      ">epoch=1130, lrate=0.300, error=0.002\n",
      ">epoch=1131, lrate=0.300, error=0.002\n",
      ">epoch=1132, lrate=0.300, error=0.002\n",
      ">epoch=1133, lrate=0.300, error=0.002\n",
      ">epoch=1134, lrate=0.300, error=0.002\n",
      ">epoch=1135, lrate=0.300, error=0.002\n",
      ">epoch=1136, lrate=0.300, error=0.002\n",
      ">epoch=1137, lrate=0.300, error=0.002\n",
      ">epoch=1138, lrate=0.300, error=0.002\n",
      ">epoch=1139, lrate=0.300, error=0.002\n",
      ">epoch=1140, lrate=0.300, error=0.002\n",
      ">epoch=1141, lrate=0.300, error=0.002\n",
      ">epoch=1142, lrate=0.300, error=0.002\n",
      ">epoch=1143, lrate=0.300, error=0.002\n",
      ">epoch=1144, lrate=0.300, error=0.002\n",
      ">epoch=1145, lrate=0.300, error=0.002\n",
      ">epoch=1146, lrate=0.300, error=0.002\n",
      ">epoch=1147, lrate=0.300, error=0.002\n",
      ">epoch=1148, lrate=0.300, error=0.002\n",
      ">epoch=1149, lrate=0.300, error=0.002\n",
      ">epoch=1150, lrate=0.300, error=0.002\n",
      ">epoch=1151, lrate=0.300, error=0.002\n",
      ">epoch=1152, lrate=0.300, error=0.002\n",
      ">epoch=1153, lrate=0.300, error=0.002\n",
      ">epoch=1154, lrate=0.300, error=0.002\n",
      ">epoch=1155, lrate=0.300, error=0.002\n",
      ">epoch=1156, lrate=0.300, error=0.002\n",
      ">epoch=1157, lrate=0.300, error=0.002\n",
      ">epoch=1158, lrate=0.300, error=0.002\n",
      ">epoch=1159, lrate=0.300, error=0.002\n",
      ">epoch=1160, lrate=0.300, error=0.002\n",
      ">epoch=1161, lrate=0.300, error=0.002\n",
      ">epoch=1162, lrate=0.300, error=0.002\n",
      ">epoch=1163, lrate=0.300, error=0.002\n",
      ">epoch=1164, lrate=0.300, error=0.002\n",
      ">epoch=1165, lrate=0.300, error=0.002\n",
      ">epoch=1166, lrate=0.300, error=0.002\n",
      ">epoch=1167, lrate=0.300, error=0.002\n",
      ">epoch=1168, lrate=0.300, error=0.002\n",
      ">epoch=1169, lrate=0.300, error=0.002\n",
      ">epoch=1170, lrate=0.300, error=0.002\n",
      ">epoch=1171, lrate=0.300, error=0.002\n",
      ">epoch=1172, lrate=0.300, error=0.002\n",
      ">epoch=1173, lrate=0.300, error=0.002\n",
      ">epoch=1174, lrate=0.300, error=0.002\n",
      ">epoch=1175, lrate=0.300, error=0.002\n",
      ">epoch=1176, lrate=0.300, error=0.002\n",
      ">epoch=1177, lrate=0.300, error=0.002\n",
      ">epoch=1178, lrate=0.300, error=0.002\n",
      ">epoch=1179, lrate=0.300, error=0.002\n",
      ">epoch=1180, lrate=0.300, error=0.002\n",
      ">epoch=1181, lrate=0.300, error=0.002\n",
      ">epoch=1182, lrate=0.300, error=0.002\n",
      ">epoch=1183, lrate=0.300, error=0.002\n",
      ">epoch=1184, lrate=0.300, error=0.002\n",
      ">epoch=1185, lrate=0.300, error=0.002\n",
      ">epoch=1186, lrate=0.300, error=0.002\n",
      ">epoch=1187, lrate=0.300, error=0.002\n",
      ">epoch=1188, lrate=0.300, error=0.002\n",
      ">epoch=1189, lrate=0.300, error=0.002\n",
      ">epoch=1190, lrate=0.300, error=0.002\n",
      ">epoch=1191, lrate=0.300, error=0.002\n",
      ">epoch=1192, lrate=0.300, error=0.002\n",
      ">epoch=1193, lrate=0.300, error=0.002\n",
      ">epoch=1194, lrate=0.300, error=0.002\n",
      ">epoch=1195, lrate=0.300, error=0.002\n",
      ">epoch=1196, lrate=0.300, error=0.002\n",
      ">epoch=1197, lrate=0.300, error=0.002\n",
      ">epoch=1198, lrate=0.300, error=0.002\n",
      ">epoch=1199, lrate=0.300, error=0.002\n",
      ">epoch=1200, lrate=0.300, error=0.002\n",
      ">epoch=1201, lrate=0.300, error=0.002\n",
      ">epoch=1202, lrate=0.300, error=0.002\n",
      ">epoch=1203, lrate=0.300, error=0.002\n",
      ">epoch=1204, lrate=0.300, error=0.002\n",
      ">epoch=1205, lrate=0.300, error=0.002\n",
      ">epoch=1206, lrate=0.300, error=0.002\n",
      ">epoch=1207, lrate=0.300, error=0.002\n",
      ">epoch=1208, lrate=0.300, error=0.002\n",
      ">epoch=1209, lrate=0.300, error=0.002\n",
      ">epoch=1210, lrate=0.300, error=0.002\n",
      ">epoch=1211, lrate=0.300, error=0.002\n",
      ">epoch=1212, lrate=0.300, error=0.002\n",
      ">epoch=1213, lrate=0.300, error=0.002\n",
      ">epoch=1214, lrate=0.300, error=0.002\n",
      ">epoch=1215, lrate=0.300, error=0.002\n",
      ">epoch=1216, lrate=0.300, error=0.002\n",
      ">epoch=1217, lrate=0.300, error=0.002\n",
      ">epoch=1218, lrate=0.300, error=0.002\n",
      ">epoch=1219, lrate=0.300, error=0.002\n",
      ">epoch=1220, lrate=0.300, error=0.002\n",
      ">epoch=1221, lrate=0.300, error=0.002\n",
      ">epoch=1222, lrate=0.300, error=0.002\n",
      ">epoch=1223, lrate=0.300, error=0.002\n",
      ">epoch=1224, lrate=0.300, error=0.002\n",
      ">epoch=1225, lrate=0.300, error=0.002\n",
      ">epoch=1226, lrate=0.300, error=0.002\n",
      ">epoch=1227, lrate=0.300, error=0.002\n",
      ">epoch=1228, lrate=0.300, error=0.002\n",
      ">epoch=1229, lrate=0.300, error=0.002\n",
      ">epoch=1230, lrate=0.300, error=0.002\n",
      ">epoch=1231, lrate=0.300, error=0.002\n",
      ">epoch=1232, lrate=0.300, error=0.002\n",
      ">epoch=1233, lrate=0.300, error=0.002\n",
      ">epoch=1234, lrate=0.300, error=0.002\n",
      ">epoch=1235, lrate=0.300, error=0.002\n",
      ">epoch=1236, lrate=0.300, error=0.002\n",
      ">epoch=1237, lrate=0.300, error=0.002\n",
      ">epoch=1238, lrate=0.300, error=0.002\n",
      ">epoch=1239, lrate=0.300, error=0.002\n",
      ">epoch=1240, lrate=0.300, error=0.002\n",
      ">epoch=1241, lrate=0.300, error=0.002\n",
      ">epoch=1242, lrate=0.300, error=0.002\n",
      ">epoch=1243, lrate=0.300, error=0.002\n",
      ">epoch=1244, lrate=0.300, error=0.002\n",
      ">epoch=1245, lrate=0.300, error=0.002\n",
      ">epoch=1246, lrate=0.300, error=0.002\n",
      ">epoch=1247, lrate=0.300, error=0.002\n",
      ">epoch=1248, lrate=0.300, error=0.002\n",
      ">epoch=1249, lrate=0.300, error=0.002\n",
      ">epoch=1250, lrate=0.300, error=0.002\n",
      ">epoch=1251, lrate=0.300, error=0.002\n",
      ">epoch=1252, lrate=0.300, error=0.002\n",
      ">epoch=1253, lrate=0.300, error=0.002\n",
      ">epoch=1254, lrate=0.300, error=0.002\n",
      ">epoch=1255, lrate=0.300, error=0.002\n",
      ">epoch=1256, lrate=0.300, error=0.002\n",
      ">epoch=1257, lrate=0.300, error=0.002\n",
      ">epoch=1258, lrate=0.300, error=0.002\n",
      ">epoch=1259, lrate=0.300, error=0.002\n",
      ">epoch=1260, lrate=0.300, error=0.002\n",
      ">epoch=1261, lrate=0.300, error=0.002\n",
      ">epoch=1262, lrate=0.300, error=0.002\n",
      ">epoch=1263, lrate=0.300, error=0.002\n",
      ">epoch=1264, lrate=0.300, error=0.002\n",
      ">epoch=1265, lrate=0.300, error=0.002\n",
      ">epoch=1266, lrate=0.300, error=0.002\n",
      ">epoch=1267, lrate=0.300, error=0.002\n",
      ">epoch=1268, lrate=0.300, error=0.002\n",
      ">epoch=1269, lrate=0.300, error=0.002\n",
      ">epoch=1270, lrate=0.300, error=0.002\n",
      ">epoch=1271, lrate=0.300, error=0.002\n",
      ">epoch=1272, lrate=0.300, error=0.002\n",
      ">epoch=1273, lrate=0.300, error=0.002\n",
      ">epoch=1274, lrate=0.300, error=0.002\n",
      ">epoch=1275, lrate=0.300, error=0.002\n",
      ">epoch=1276, lrate=0.300, error=0.002\n",
      ">epoch=1277, lrate=0.300, error=0.002\n",
      ">epoch=1278, lrate=0.300, error=0.002\n",
      ">epoch=1279, lrate=0.300, error=0.002\n",
      ">epoch=1280, lrate=0.300, error=0.002\n",
      ">epoch=1281, lrate=0.300, error=0.002\n",
      ">epoch=1282, lrate=0.300, error=0.002\n",
      ">epoch=1283, lrate=0.300, error=0.002\n",
      ">epoch=1284, lrate=0.300, error=0.002\n",
      ">epoch=1285, lrate=0.300, error=0.002\n",
      ">epoch=1286, lrate=0.300, error=0.002\n",
      ">epoch=1287, lrate=0.300, error=0.002\n",
      ">epoch=1288, lrate=0.300, error=0.002\n",
      ">epoch=1289, lrate=0.300, error=0.002\n",
      ">epoch=1290, lrate=0.300, error=0.002\n",
      ">epoch=1291, lrate=0.300, error=0.002\n",
      ">epoch=1292, lrate=0.300, error=0.002\n",
      ">epoch=1293, lrate=0.300, error=0.002\n",
      ">epoch=1294, lrate=0.300, error=0.002\n",
      ">epoch=1295, lrate=0.300, error=0.002\n",
      ">epoch=1296, lrate=0.300, error=0.002\n",
      ">epoch=1297, lrate=0.300, error=0.002\n",
      ">epoch=1298, lrate=0.300, error=0.002\n",
      ">epoch=1299, lrate=0.300, error=0.002\n",
      ">epoch=1300, lrate=0.300, error=0.002\n",
      ">epoch=1301, lrate=0.300, error=0.002\n",
      ">epoch=1302, lrate=0.300, error=0.002\n",
      ">epoch=1303, lrate=0.300, error=0.002\n",
      ">epoch=1304, lrate=0.300, error=0.002\n",
      ">epoch=1305, lrate=0.300, error=0.002\n",
      ">epoch=1306, lrate=0.300, error=0.002\n",
      ">epoch=1307, lrate=0.300, error=0.002\n",
      ">epoch=1308, lrate=0.300, error=0.002\n",
      ">epoch=1309, lrate=0.300, error=0.002\n",
      ">epoch=1310, lrate=0.300, error=0.002\n",
      ">epoch=1311, lrate=0.300, error=0.002\n",
      ">epoch=1312, lrate=0.300, error=0.002\n",
      ">epoch=1313, lrate=0.300, error=0.002\n",
      ">epoch=1314, lrate=0.300, error=0.002\n",
      ">epoch=1315, lrate=0.300, error=0.002\n",
      ">epoch=1316, lrate=0.300, error=0.002\n",
      ">epoch=1317, lrate=0.300, error=0.002\n",
      ">epoch=1318, lrate=0.300, error=0.002\n",
      ">epoch=1319, lrate=0.300, error=0.002\n",
      ">epoch=1320, lrate=0.300, error=0.002\n",
      ">epoch=1321, lrate=0.300, error=0.002\n",
      ">epoch=1322, lrate=0.300, error=0.002\n",
      ">epoch=1323, lrate=0.300, error=0.002\n",
      ">epoch=1324, lrate=0.300, error=0.002\n",
      ">epoch=1325, lrate=0.300, error=0.002\n",
      ">epoch=1326, lrate=0.300, error=0.002\n",
      ">epoch=1327, lrate=0.300, error=0.002\n",
      ">epoch=1328, lrate=0.300, error=0.002\n",
      ">epoch=1329, lrate=0.300, error=0.002\n",
      ">epoch=1330, lrate=0.300, error=0.002\n",
      ">epoch=1331, lrate=0.300, error=0.002\n",
      ">epoch=1332, lrate=0.300, error=0.002\n",
      ">epoch=1333, lrate=0.300, error=0.002\n",
      ">epoch=1334, lrate=0.300, error=0.002\n",
      ">epoch=1335, lrate=0.300, error=0.002\n",
      ">epoch=1336, lrate=0.300, error=0.002\n",
      ">epoch=1337, lrate=0.300, error=0.002\n",
      ">epoch=1338, lrate=0.300, error=0.002\n",
      ">epoch=1339, lrate=0.300, error=0.002\n",
      ">epoch=1340, lrate=0.300, error=0.002\n",
      ">epoch=1341, lrate=0.300, error=0.002\n",
      ">epoch=1342, lrate=0.300, error=0.002\n",
      ">epoch=1343, lrate=0.300, error=0.002\n",
      ">epoch=1344, lrate=0.300, error=0.002\n",
      ">epoch=1345, lrate=0.300, error=0.002\n",
      ">epoch=1346, lrate=0.300, error=0.002\n",
      ">epoch=1347, lrate=0.300, error=0.002\n",
      ">epoch=1348, lrate=0.300, error=0.002\n",
      ">epoch=1349, lrate=0.300, error=0.002\n",
      ">epoch=1350, lrate=0.300, error=0.002\n",
      ">epoch=1351, lrate=0.300, error=0.002\n",
      ">epoch=1352, lrate=0.300, error=0.002\n",
      ">epoch=1353, lrate=0.300, error=0.002\n",
      ">epoch=1354, lrate=0.300, error=0.002\n",
      ">epoch=1355, lrate=0.300, error=0.002\n",
      ">epoch=1356, lrate=0.300, error=0.002\n",
      ">epoch=1357, lrate=0.300, error=0.002\n",
      ">epoch=1358, lrate=0.300, error=0.002\n",
      ">epoch=1359, lrate=0.300, error=0.002\n",
      ">epoch=1360, lrate=0.300, error=0.002\n",
      ">epoch=1361, lrate=0.300, error=0.002\n",
      ">epoch=1362, lrate=0.300, error=0.002\n",
      ">epoch=1363, lrate=0.300, error=0.002\n",
      ">epoch=1364, lrate=0.300, error=0.002\n",
      ">epoch=1365, lrate=0.300, error=0.002\n",
      ">epoch=1366, lrate=0.300, error=0.002\n",
      ">epoch=1367, lrate=0.300, error=0.002\n",
      ">epoch=1368, lrate=0.300, error=0.002\n",
      ">epoch=1369, lrate=0.300, error=0.002\n",
      ">epoch=1370, lrate=0.300, error=0.002\n",
      ">epoch=1371, lrate=0.300, error=0.002\n",
      ">epoch=1372, lrate=0.300, error=0.002\n",
      ">epoch=1373, lrate=0.300, error=0.002\n",
      ">epoch=1374, lrate=0.300, error=0.002\n",
      ">epoch=1375, lrate=0.300, error=0.002\n",
      ">epoch=1376, lrate=0.300, error=0.002\n",
      ">epoch=1377, lrate=0.300, error=0.002\n",
      ">epoch=1378, lrate=0.300, error=0.002\n",
      ">epoch=1379, lrate=0.300, error=0.002\n",
      ">epoch=1380, lrate=0.300, error=0.002\n",
      ">epoch=1381, lrate=0.300, error=0.002\n",
      ">epoch=1382, lrate=0.300, error=0.002\n",
      ">epoch=1383, lrate=0.300, error=0.002\n",
      ">epoch=1384, lrate=0.300, error=0.002\n",
      ">epoch=1385, lrate=0.300, error=0.002\n",
      ">epoch=1386, lrate=0.300, error=0.002\n",
      ">epoch=1387, lrate=0.300, error=0.002\n",
      ">epoch=1388, lrate=0.300, error=0.002\n",
      ">epoch=1389, lrate=0.300, error=0.002\n",
      ">epoch=1390, lrate=0.300, error=0.002\n",
      ">epoch=1391, lrate=0.300, error=0.002\n",
      ">epoch=1392, lrate=0.300, error=0.002\n",
      ">epoch=1393, lrate=0.300, error=0.002\n",
      ">epoch=1394, lrate=0.300, error=0.002\n",
      ">epoch=1395, lrate=0.300, error=0.002\n",
      ">epoch=1396, lrate=0.300, error=0.002\n",
      ">epoch=1397, lrate=0.300, error=0.002\n",
      ">epoch=1398, lrate=0.300, error=0.002\n",
      ">epoch=1399, lrate=0.300, error=0.002\n",
      ">epoch=1400, lrate=0.300, error=0.002\n",
      ">epoch=1401, lrate=0.300, error=0.002\n",
      ">epoch=1402, lrate=0.300, error=0.002\n",
      ">epoch=1403, lrate=0.300, error=0.002\n",
      ">epoch=1404, lrate=0.300, error=0.002\n",
      ">epoch=1405, lrate=0.300, error=0.002\n",
      ">epoch=1406, lrate=0.300, error=0.002\n",
      ">epoch=1407, lrate=0.300, error=0.002\n",
      ">epoch=1408, lrate=0.300, error=0.002\n",
      ">epoch=1409, lrate=0.300, error=0.002\n",
      ">epoch=1410, lrate=0.300, error=0.002\n",
      ">epoch=1411, lrate=0.300, error=0.002\n",
      ">epoch=1412, lrate=0.300, error=0.002\n",
      ">epoch=1413, lrate=0.300, error=0.002\n",
      ">epoch=1414, lrate=0.300, error=0.002\n",
      ">epoch=1415, lrate=0.300, error=0.002\n",
      ">epoch=1416, lrate=0.300, error=0.002\n",
      ">epoch=1417, lrate=0.300, error=0.002\n",
      ">epoch=1418, lrate=0.300, error=0.002\n",
      ">epoch=1419, lrate=0.300, error=0.002\n",
      ">epoch=1420, lrate=0.300, error=0.002\n",
      ">epoch=1421, lrate=0.300, error=0.002\n",
      ">epoch=1422, lrate=0.300, error=0.002\n",
      ">epoch=1423, lrate=0.300, error=0.001\n",
      ">epoch=1424, lrate=0.300, error=0.001\n",
      ">epoch=1425, lrate=0.300, error=0.001\n",
      ">epoch=1426, lrate=0.300, error=0.001\n",
      ">epoch=1427, lrate=0.300, error=0.001\n",
      ">epoch=1428, lrate=0.300, error=0.001\n",
      ">epoch=1429, lrate=0.300, error=0.001\n",
      ">epoch=1430, lrate=0.300, error=0.001\n",
      ">epoch=1431, lrate=0.300, error=0.001\n",
      ">epoch=1432, lrate=0.300, error=0.001\n",
      ">epoch=1433, lrate=0.300, error=0.001\n",
      ">epoch=1434, lrate=0.300, error=0.001\n",
      ">epoch=1435, lrate=0.300, error=0.001\n",
      ">epoch=1436, lrate=0.300, error=0.001\n",
      ">epoch=1437, lrate=0.300, error=0.001\n",
      ">epoch=1438, lrate=0.300, error=0.001\n",
      ">epoch=1439, lrate=0.300, error=0.001\n",
      ">epoch=1440, lrate=0.300, error=0.001\n",
      ">epoch=1441, lrate=0.300, error=0.001\n",
      ">epoch=1442, lrate=0.300, error=0.001\n",
      ">epoch=1443, lrate=0.300, error=0.001\n",
      ">epoch=1444, lrate=0.300, error=0.001\n",
      ">epoch=1445, lrate=0.300, error=0.001\n",
      ">epoch=1446, lrate=0.300, error=0.001\n",
      ">epoch=1447, lrate=0.300, error=0.001\n",
      ">epoch=1448, lrate=0.300, error=0.001\n",
      ">epoch=1449, lrate=0.300, error=0.001\n",
      ">epoch=1450, lrate=0.300, error=0.001\n",
      ">epoch=1451, lrate=0.300, error=0.001\n",
      ">epoch=1452, lrate=0.300, error=0.001\n",
      ">epoch=1453, lrate=0.300, error=0.001\n",
      ">epoch=1454, lrate=0.300, error=0.001\n",
      ">epoch=1455, lrate=0.300, error=0.001\n",
      ">epoch=1456, lrate=0.300, error=0.001\n",
      ">epoch=1457, lrate=0.300, error=0.001\n",
      ">epoch=1458, lrate=0.300, error=0.001\n",
      ">epoch=1459, lrate=0.300, error=0.001\n",
      ">epoch=1460, lrate=0.300, error=0.001\n",
      ">epoch=1461, lrate=0.300, error=0.001\n",
      ">epoch=1462, lrate=0.300, error=0.001\n",
      ">epoch=1463, lrate=0.300, error=0.001\n",
      ">epoch=1464, lrate=0.300, error=0.001\n",
      ">epoch=1465, lrate=0.300, error=0.001\n",
      ">epoch=1466, lrate=0.300, error=0.001\n",
      ">epoch=1467, lrate=0.300, error=0.001\n",
      ">epoch=1468, lrate=0.300, error=0.001\n",
      ">epoch=1469, lrate=0.300, error=0.001\n",
      ">epoch=1470, lrate=0.300, error=0.001\n",
      ">epoch=1471, lrate=0.300, error=0.001\n",
      ">epoch=1472, lrate=0.300, error=0.001\n",
      ">epoch=1473, lrate=0.300, error=0.001\n",
      ">epoch=1474, lrate=0.300, error=0.001\n",
      ">epoch=1475, lrate=0.300, error=0.001\n",
      ">epoch=1476, lrate=0.300, error=0.001\n",
      ">epoch=1477, lrate=0.300, error=0.001\n",
      ">epoch=1478, lrate=0.300, error=0.001\n",
      ">epoch=1479, lrate=0.300, error=0.001\n",
      ">epoch=1480, lrate=0.300, error=0.001\n",
      ">epoch=1481, lrate=0.300, error=0.001\n",
      ">epoch=1482, lrate=0.300, error=0.001\n",
      ">epoch=1483, lrate=0.300, error=0.001\n",
      ">epoch=1484, lrate=0.300, error=0.001\n",
      ">epoch=1485, lrate=0.300, error=0.001\n",
      ">epoch=1486, lrate=0.300, error=0.001\n",
      ">epoch=1487, lrate=0.300, error=0.001\n",
      ">epoch=1488, lrate=0.300, error=0.001\n",
      ">epoch=1489, lrate=0.300, error=0.001\n",
      ">epoch=1490, lrate=0.300, error=0.001\n",
      ">epoch=1491, lrate=0.300, error=0.001\n",
      ">epoch=1492, lrate=0.300, error=0.001\n",
      ">epoch=1493, lrate=0.300, error=0.001\n",
      ">epoch=1494, lrate=0.300, error=0.001\n",
      ">epoch=1495, lrate=0.300, error=0.001\n",
      ">epoch=1496, lrate=0.300, error=0.001\n",
      ">epoch=1497, lrate=0.300, error=0.001\n",
      ">epoch=1498, lrate=0.300, error=0.001\n",
      ">epoch=1499, lrate=0.300, error=0.001\n",
      "[-1.3447030424565445, 2.3335933252139123, -3.441441412255851]\n"
     ]
    }
   ],
   "source": [
    "l_rate = 0.3\n",
    "n_epoch = 1500\n",
    "coef = coefficients_sgd(dataset, l_rate, n_epoch)\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes ver cómo el error sigue disminuyendo incluso en la época final. Probablemente podríamos entrenar durante mucho más tiempo (más épocas) o aumentar la cantidad que actualizamos los coeficientes en cada época (ritmo de aprendizaje más alto).\n",
    "\n",
    "Experimente y vea lo que se le ocurre.\n",
    "\n",
    "Ahora, apliquemos este algoritmo en un conjunto de datos real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predicción de la diabetes\n",
    "\n",
    "En esta sección, entrenaremos un modelo de regresión logística utilizando el descenso de gradiente estocástico sobre el conjunto de datos de diabetes.\n",
    "\n",
    "El ejemplo asume que una copia CSV del conjunto de datos está en el directorio de trabajo actual con el nombre de archivo nb4-diabetes.csv.\n",
    "\n",
    "El conjunto de datos se carga primero, los valores de las cadenas se convierten a numéricos y cada columna se normaliza a valores en el rango de 0 a 1. Esto se logra con las funciones <code>helper load_csv()</code> y <code>str_column_to_float()</code> para cargar y preparar el dataset y <code>dataset_minmax()</code> y <code>normalize_dataset()</code> para normalizarlo.\n",
    "\n",
    "Usaremos la validación cruzada de k-fold para estimar el rendimiento del modelo aprendido en datos no vistos. Esto significa que construiremos y evaluaremos los modelos k y estimaremos el rendimiento como el rendimiento medio del modelo. La exactitud de la clasificación se utilizará para evaluar cada modelo. Estos comportamientos se proporcionan en las funciones de ayuda <code>cross_validation_split()</code>, <code>accuracy_metric()</code> y <code>evaluate_algorithm()</code>.\n",
    "\n",
    "Usaremos las funciones <code>predict()</code>, <code>coefficients_sgd()</code> creadas anteriormente y una nueva función <code>logistic_regression()</code> para entrenar el modelo.\n",
    "\n",
    "A continuación se muestra el ejemplo completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color  [0.16413876047107268, 0.7102440591612986, 0.16162714876568007]\n",
      "color  [0.09305344076397803, 0.635972475177856, 0.2757955909147405]\n",
      "color  [0.3044032842583163, 0.5280927956678594, 0.23723352615554094]\n",
      "color  [0.3339454253693611, 0.0685541709876416, 0.6991950335404097]\n",
      "color  [0.9103397840499711, 0.6587849510327589, 0.4679366313779273]\n",
      "Scores: [73.8562091503268, 78.43137254901961, 81.69934640522875, 75.81699346405229, 75.81699346405229]\n",
      "Mean Accuracy: 77.124%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic Regression on Diabetes Dataset\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from random import random\n",
    "from csv import reader\n",
    "from math import exp\n",
    "import numpy as np\n",
    " \n",
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset\n",
    " \n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())\n",
    " \n",
    "# Find the min and max values for each column\n",
    "def dataset_minmax(dataset):\n",
    "    minmax = list()\n",
    "    for i in range(len(dataset[0])):\n",
    "        col_values = [row[i] for row in dataset]\n",
    "        value_min = min(col_values)\n",
    "        value_max = max(col_values)\n",
    "        minmax.append([value_min, value_max])\n",
    "    return minmax\n",
    " \n",
    "# Rescale dataset columns to the range 0-1\n",
    "def normalize_dataset(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    " \n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    " \n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    " \n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "    return scores\n",
    " \n",
    "# Make a prediction with coefficients\n",
    "def predict(row, coefficients):\n",
    "    yhat = coefficients[0]\n",
    "    for i in range(len(row)-1):\n",
    "        yhat += coefficients[i + 1] * row[i]\n",
    "    return 1.0 / (1.0 + exp(-yhat))\n",
    " \n",
    "# Estimate logistic regression coefficients using stochastic gradient descent\n",
    "def coefficients_sgd(train, l_rate, n_epoch):\n",
    "    coef = [0.0 for i in range(len(train[0]))]\n",
    "    color= [random(),random(),random()]\n",
    "    for epoch in range(n_epoch):\n",
    "        #print(\"epoch:\"+str(epoch))\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            yhat = predict(row, coef)\n",
    "            error = row[-1] - yhat\n",
    "            sum_error += error**2\n",
    "            #print('Error%.3f' %error)\n",
    "            coef[0] = coef[0] + l_rate * error * yhat * (1.0 - yhat)\n",
    "            #print(\"coef_0:\"+str(coef[0]))\n",
    "            for i in range(len(row)-1):\n",
    "                coef[i + 1] = coef[i + 1] + l_rate * error * yhat * (1.0 - yhat) * row[i]\n",
    "        sum_error = np.sqrt(sum_error/len(train))\n",
    "        \n",
    "        plt.scatter(x=epoch, y=sum_error, c=color, s=10)\n",
    "        \n",
    "        #print(\"Epoch %i, RMSE %f\" % (epoch, sum_error))\n",
    "    print(\"color \",color)\n",
    "    return coef\n",
    "\n",
    " \n",
    "# Linear Regression Algorithm With Stochastic Gradient Descent\n",
    "def logistic_regression(train, test, l_rate, n_epoch):\n",
    "    predictions = list()\n",
    "    coef = coefficients_sgd(train, l_rate, n_epoch)\n",
    "    for row in test:\n",
    "        yhat = predict(row, coef)\n",
    "        yhat = round(yhat)\n",
    "        predictions.append(yhat)\n",
    "    return(predictions)\n",
    " \n",
    "# Test the logistic regression algorithm on the diabetes dataset\n",
    "seed(1)\n",
    "# load and prepare data\n",
    "filename = 'nb5-diabetes.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0])):\n",
    "    str_column_to_float(dataset, i)\n",
    "# normalize\n",
    "minmax = dataset_minmax(dataset)\n",
    "normalize_dataset(dataset, minmax)\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "l_rate = 0.1\n",
    "n_epoch = 100\n",
    "scores = evaluate_algorithm(dataset, logistic_regression, n_folds, l_rate, n_epoch)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizó un valor k de 5 para la validación cruzada, dando a cada muestra 768/5 = 153,6 o algo más de 150 registros para ser evaluados en cada iteración. Se eligió una tasa de aprendizaje de 0,1 y 100 épocas de entrenamiento con un poco de experimentación.\n",
    "\n",
    "Puedes probar tus propias configuraciones y ver si puedes superar mi puntuación.\n",
    "\n",
    "Al ejecutar este ejemplo, se imprimen las puntuaciones de cada uno de los 5 pliegues de validación cruzada y, a continuación, se imprime la precisión de clasificación media."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Pregunta</b>:\n",
    "\n",
    "Con Pandas y Matplotlib, dibujar una curva que representa la tasa de error de la regresión logística según el epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(Esta arriba, el error es RMSE, los colores van segun los folds)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
